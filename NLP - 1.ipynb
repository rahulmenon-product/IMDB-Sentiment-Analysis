{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17be9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\FC316LE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce4ee9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, this is Rahul. I am learning NLP!\n",
      "Please do support me.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tokenization Example\n",
    "\n",
    "corpus = '''Hello, this is Rahul. I am learning NLP!\n",
    "Please do support me.\n",
    "'''\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2662b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello, this is Rahul.', 'I am learning NLP!', 'Please do support me.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize   #sent_tokenize will help us convert paragraphs into sentences\n",
    "sentences = sent_tokenize(corpus)\n",
    "print(sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d7474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\FC316LE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\FC316LE\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello, this is Rahul.', 'I am learning NLP.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fbf5386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, this is Rahul.\n",
      "I am learning NLP!\n",
      "Please do support me.\n"
     ]
    }
   ],
   "source": [
    "#to iterate through these sentences\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aeac99e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'this', 'is', 'Rahul', '.', 'I', 'am', 'learning', 'NLP', '!', 'Please', 'do', 'support', 'me', '.']\n"
     ]
    }
   ],
   "source": [
    "#word tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "words = word_tokenize(corpus)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70404249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      ",\n",
      "this\n",
      "is\n",
      "Rahul\n",
      ".\n",
      "I\n",
      "am\n",
      "learning\n",
      "NLP\n",
      "!\n",
      "Please\n",
      "do\n",
      "support\n",
      "me\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0df5b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'Rahul.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'learning',\n",
       " 'NLP',\n",
       " '!',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'support',\n",
       " 'me',\n",
       " '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer             #with the help of TreeBankTkn full stops wont be treated as separate words.\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1227399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goes--->goe\n",
      "going--->go\n",
      "shopping--->shop\n",
      "shop--->shop\n",
      "however--->howev\n",
      "history--->histori\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "words = ['goes','going','shopping','shop','however','history']\n",
    "\n",
    "#create an object first\n",
    "stemming = PorterStemmer()\n",
    "\n",
    "#iterating\n",
    "for word in words:\n",
    "    print(word+\"--->\"+stemming.stem(word))       #we have to use the stem() with the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94970338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['understand', 'ingunderstand', 'go', 'eat']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "regx_stemmer = RegexpStemmer('ing$|es$|able$',min=4)   # $ at the end indicates to stem out ing which comes in end only\n",
    "a = regx_stemmer.stem(\"understanding\")\n",
    "b = regx_stemmer.stem(\"ingunderstand\")\n",
    "c = regx_stemmer.stem(\"goes\")\n",
    "d = regx_stemmer.stem(\"eatable\")\n",
    "\n",
    "stem_list = [a,b,c,d]\n",
    "print(stem_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3eac246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goes-->goe\n",
      "going-->go\n",
      "shopping-->shop\n",
      "shop-->shop\n",
      "however-->howev\n",
      "history-->histori\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snow_stem = SnowballStemmer('english')\n",
    "\n",
    "for word in words:\n",
    "    print(word+\"-->\"+snow_stem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3444243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\FC316LE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\FC316LE\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e4bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goes-->go\n",
      "going-->go\n",
      "shopping-->shop\n",
      "however-->however\n",
      "history-->history\n",
      "walking-->walk\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "#define a object\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words = ['goes','going','shopping','however','history',\"walking\"]\n",
    "\n",
    "for word in words:\n",
    "    print(word+\"-->\"+lemmatizer.lemmatize(word,pos = 'v'))         #Give the pos value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a03a5c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\FC316LE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e4e3ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to find the list of stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70511aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' The children were playing in the gardens while their parents watched happily.', 'Some dogs were running around, chasing balls and barking loudly.', 'It was one of the most joyful afternoons they had experienced in months.']\n"
     ]
    }
   ],
   "source": [
    "paragraph = ''' The children were playing in the gardens while their parents watched happily. \n",
    "Some dogs were running around, chasing balls and barking loudly.\n",
    " It was one of the most joyful afternoons they had experienced in months.\n",
    "'''\n",
    "\n",
    "from nltk.tokenize import sent_tokenize   #sent_tokenize will help us convert paragraphs into sentences\n",
    "sentences = sent_tokenize(paragraph)\n",
    "print(sentences)\n",
    "\n",
    "from nltk.stem import SnowballStemmer     #to use snowball stemming\n",
    "snow_stem = SnowballStemmer('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "442f7e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply stopwards, filter then snowball stemming\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])            #converting each sentences to words and assigning to variable words\n",
    "    words = [snow_stem.stem(word) for word in words if word not in set(stopwords.words('english'))]     #set is used to collect values and remove duplicates\n",
    "    sentences[i] = ' '.join(words) #all the converted list of words are made again into sentences with spaces between each words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65ffe1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the children play garden parent watch happili .',\n",
       " 'some dog run around , chase ball bark loud .',\n",
       " 'it one joy afternoon experienc month .']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4df1c337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' The children were playing in the gardens while their parents watched happily.', 'Some dogs were running around, chasing balls and barking loudly.', 'It was one of the most joyful afternoons they had experienced in months.']\n"
     ]
    }
   ],
   "source": [
    "#applying lemmatization to the same paragraph\n",
    "\n",
    "paragraph = ''' The children were playing in the gardens while their parents watched happily. \n",
    "Some dogs were running around, chasing balls and barking loudly.\n",
    " It was one of the most joyful afternoons they had experienced in months.\n",
    "'''\n",
    "\n",
    "from nltk.tokenize import sent_tokenize   #sent_tokenize will help us convert paragraphs into sentences\n",
    "sentences = sent_tokenize(paragraph)\n",
    "print(sentences)\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer     #to use snowball stemming\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b06f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply stopwards, filter then lemmatization\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])            #converting each sentences to words and assigning to variable words\n",
    "    words = [lemmatizer.lemmatize(word.lower(),pos = 'v') for word in words if word not in set(stopwords.words('english'))]     #set is used to collect values and remove duplicates\n",
    "    sentences[i] = ' '.join(words) #all the converted list of words are made again into sentences with spaces between each words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c90b9376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the child play garden parent watch happily .',\n",
       " 'some dog run around , chase ball bark loudly .',\n",
       " 'it one joyful afternoon experience month .']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2456a1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' The children were playing in the gardens while their parents watched happily.', 'Some dogs were running around, chasing balls and barking loudly.', 'It was one of the most joyful afternoons they had experienced in months.']\n"
     ]
    }
   ],
   "source": [
    "paragraph = ''' The children were playing in the gardens while their parents watched happily. \n",
    "Some dogs were running around, chasing balls and barking loudly.\n",
    " It was one of the most joyful afternoons they had experienced in months.\n",
    "'''\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "print(sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f10e825f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\FC316LE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\FC316LE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\FC316LE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# For newer NLTK versions (post-3.8)\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# You still need these for your code\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a0c130b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('children', 'NNS'), ('playing', 'VBG'), ('gardens', 'NNS'), ('parents', 'NNS'), ('watched', 'VBD'), ('happily', 'RB'), ('.', '.')]\n",
      "[('Some', 'DT'), ('dogs', 'NNS'), ('running', 'VBG'), ('around', 'RB'), (',', ','), ('chasing', 'VBG'), ('balls', 'NNS'), ('barking', 'VBG'), ('loudly', 'RB'), ('.', '.')]\n",
      "[('It', 'PRP'), ('one', 'CD'), ('joyful', 'JJ'), ('afternoons', 'NNS'), ('experienced', 'VBD'), ('months', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Will find out the post_tag for each words\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])            #converting each sentences to words and assigning to variable words\n",
    "    words = [word for word in words if word not in set(stopwords.words('english'))]     #set is used to collect values and remove duplicates\n",
    "    pos_tag = nltk.pos_tag(words)\n",
    "    print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0cdaab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Taj', 'NNP'), ('Mahal', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('beautiful', 'JJ'), ('Monument', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "tokens = nltk.word_tokenize(\"Taj Mahal is a beautiful Monument\")\n",
    "\n",
    "# For pos_tag_sents, wrap tokens in another list\n",
    "result = nltk.pos_tag_sents([tokens])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c6be187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Taj', 'Mahal', 'is', 'a', 'beautiful', 'Monument']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Taj Mahal is a beautiful Monument\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd326c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\FC316LE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc5b5573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\FC316LE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc7ce109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Effiel', 'Tower', 'was', 'build', 'by', 'Thomas', 'Effiel', 'in', '1989', ',', 'August', '31st', 'and', 'was', 'worth', 'arond', '1', 'million', 'dollars', 'in', 'Paris', ',', 'France']\n"
     ]
    }
   ],
   "source": [
    "paragraph = \"The Effiel Tower was build by Thomas Effiel in 1989, August 31st and was worth arond 1 million dollars in Paris, France\"\n",
    "import nltk\n",
    "sentences = nltk.word_tokenize(paragraph)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87525fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words = nltk.pos_tag(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e7e8c64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     C:\\Users\\FC316LE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker_tab.zip.\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\FC316LE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')  # ne_chunk needs this dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e52cf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (ORGANIZATION Effiel/NNP Tower/NNP)\n",
      "  was/VBD\n",
      "  build/VBN\n",
      "  by/IN\n",
      "  (PERSON Thomas/NNP Effiel/NNP)\n",
      "  in/IN\n",
      "  1989/CD\n",
      "  ,/,\n",
      "  August/NNP\n",
      "  31st/CD\n",
      "  and/CC\n",
      "  was/VBD\n",
      "  worth/JJ\n",
      "  arond/RB\n",
      "  1/CD\n",
      "  million/CD\n",
      "  dollars/NNS\n",
      "  in/IN\n",
      "  (GPE Paris/NNP)\n",
      "  ,/,\n",
      "  (GPE France/NNP))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "tree = nltk.ne_chunk(tagged_words)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287eddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.ne_chunk(tagged_words).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22420f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Label                                            Message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...    ...                                                ...\n",
      "5568  spam  This is the 2nd time we have tried 2 contact u...\n",
      "5569   ham              Will ÃŒ_ b going to esplanade fr home?\n",
      "5570   ham  Pity, * was in mood for that. So...any other s...\n",
      "5571   ham  The guy did some bitching but I acted like i'd...\n",
      "5572   ham                         Rofl. Its true to its name\n",
      "\n",
      "[5573 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "text = pd.read_excel(\"spam.xlsx\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f65b2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "#object\n",
    "ps = PorterStemmer()\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in range(0,len(text)):\n",
    "    review = re.sub('[^a-zA-z]',' ',text['Message'][i])          #ro access each rows in a column we use text[message][i]\n",
    "    review = review.lower()\n",
    "    review = review.split()           #splits sentences into rows\n",
    "    review = [ps.stem(word) for word in review if word not in stopwords.words('english')]\n",
    "    review = ' '.join(review)             #words are joined to form sentences\n",
    "    corpus.append(review)\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92bf99ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point crazi avail bugi n great world la e buffet cine got amor wat',\n",
       " 'ok lar joke wif u oni',\n",
       " 'free entri wkli comp win fa cup final tkt st may text fa receiv entri question std txt rate c appli',\n",
       " 'u dun say earli hor u c alreadi say',\n",
       " 'nah think goe usf live around though',\n",
       " 'freemsg hey darl week word back like fun still tb ok xxx std chg send rcv',\n",
       " 'even brother like speak treat like aid patent',\n",
       " 'per request mell mell oru minnaminungint nurungu vettam set callertun caller press copi friend callertun',\n",
       " 'winner valu network custom select receivea prize reward claim call claim code kl valid hour',\n",
       " 'mobil month u r entitl updat latest colour mobil camera free call mobil updat co free',\n",
       " 'gonna home soon want talk stuff anymor tonight k cri enough today',\n",
       " 'six chanc win cash pound txt csh send cost p day day tsandc appli repli hl info',\n",
       " 'urgent week free membership prize jackpot txt word claim c www dbuk net lccltd pobox ldnw rw',\n",
       " 'search right word thank breather promis wont take help grant fulfil promis wonder bless time',\n",
       " 'date sunday',\n",
       " 'xxxmobilemovieclub use credit click wap link next txt messag click http wap xxxmobilemovieclub com n qjkgighjjgcbl',\n",
       " 'oh k watch',\n",
       " 'eh u rememb spell name ye v naughti make v wet',\n",
       " 'fine way u feel way gota b',\n",
       " 'england v macedonia dont miss goal team news txt ur nation team eg england tri wale scotland txt poboxox w wq',\n",
       " 'serious spell name',\n",
       " 'go tri month ha ha joke',\n",
       " '_ pay first lar da stock comin',\n",
       " 'aft finish lunch go str lor ard smth lor u finish ur lunch alreadi',\n",
       " 'ffffffffff alright way meet sooner',\n",
       " 'forc eat slice realli hungri tho suck mark get worri know sick turn pizza lol',\n",
       " 'lol alway convinc',\n",
       " 'catch bu fri egg make tea eat mom left dinner feel love',\n",
       " 'back amp pack car let know room',\n",
       " 'ahhh work vagu rememb feel like lol',\n",
       " 'wait still clear sure sarcast x want live us',\n",
       " 'yeah got v apologet n fallen actin like spoilt child got caught till go badli cheer',\n",
       " 'k tell anyth',\n",
       " 'fear faint housework quick cuppa',\n",
       " 'thank subscript rington uk mobil charg month pleas confirm repli ye repli charg',\n",
       " 'yup ok go home look time msg _ xuhui go learn nd may lesson',\n",
       " 'oop let know roommat done',\n",
       " 'see letter b car',\n",
       " 'anyth lor u decid',\n",
       " 'hello saturday go text see decid anyth tomo tri invit anyth',\n",
       " 'pl go ahead watt want sure great weekend abiola',\n",
       " 'forget tell want need crave love sweet arabian steed mmmmmm yummi',\n",
       " 'rodger burn msg tri call repli sm free nokia mobil free camcord pleas call deliveri tomorrow',\n",
       " 'see',\n",
       " 'great hope like man well endow lt gt inch',\n",
       " 'call messag miss call',\n",
       " 'get hep b immunis nigeria',\n",
       " 'fair enough anyth go',\n",
       " 'yeah hope tyler could mayb ask around bit',\n",
       " 'u know stubborn even want go hospit kept tell mark weak sucker hospit weak sucker',\n",
       " 'think first time saw class',\n",
       " 'gram usual run like lt gt half eighth smarter though get almost whole second gram lt gt',\n",
       " 'k fyi x ride earli tomorrow morn crash place tonight',\n",
       " 'wow never realiz embarass accomod thought like sinc best could alway seem happi \\\\the cave\\\\ sorri give sorri offer sorri room embarass',\n",
       " 'sm ac sptv new jersey devil detroit red wing play ice hockey correct incorrect end repli end sptv',\n",
       " 'know mallika sherawat yesterday find lt url gt',\n",
       " 'congrat year special cinema pass call c suprman v matrix starwar etc free bx ip pm dont miss',\n",
       " 'sorri call later meet',\n",
       " 'tell reach',\n",
       " 'ye gauti sehwag odi seri',\n",
       " 'gonna pick burger way home even move pain kill',\n",
       " 'ha ha ha good joke girl situat seeker',\n",
       " 'part check iq',\n",
       " 'sorri roommat took forev ok come',\n",
       " 'ok lar doubl check wif da hair dresser alreadi said wun cut v short said cut look nice',\n",
       " 'valu custom pleas advis follow recent review mob award bonu prize call',\n",
       " 'today \\\\song dedic day \\\\ song u dedic send ur valuabl frnd first rpli',\n",
       " 'urgent ur award complimentari trip eurodisinc trav aco entri claim txt di morefrmmob shracomorsglsuplt ls aj',\n",
       " 'hear new \\\\divorc barbie\\\\ come ken stuff',\n",
       " 'plane give month end',\n",
       " 'wah lucki man save money hee',\n",
       " 'finish class',\n",
       " 'hi babe im home wanna someth xx',\n",
       " 'k k perform',\n",
       " 'u call',\n",
       " 'wait machan call free',\n",
       " 'that cool gentleman treat digniti respect',\n",
       " 'like peopl much shi pa',\n",
       " 'oper lt gt',\n",
       " 'still look job much ta earn',\n",
       " 'sorri call later',\n",
       " 'k call ah',\n",
       " 'ok way home hi hi',\n",
       " 'place man',\n",
       " 'yup next stop',\n",
       " 'call later network urgnt sm',\n",
       " 'real u get yo need ticket one jacket done alreadi use multi',\n",
       " 'ye start send request make pain came back back bed doubl coin factori gotta cash nitro',\n",
       " 'realli still tonight babe',\n",
       " 'ela kano il download come wen ur free',\n",
       " 'yeah stand close tho catch someth',\n",
       " 'sorri pain ok meet anoth night spent late afternoon casualti mean done stuff moro includ time sheet sorri',\n",
       " 'smile pleasur smile pain smile troubl pour like rain smile sum hurt u smile becoz someon still love see u smile',\n",
       " 'pleas call custom servic repres pm guarante cash prize',\n",
       " 'havent plan buy later check alreadi lido got show e afternoon u finish work alreadi',\n",
       " 'free rington wait collect simpli text password \\\\mix\\\\ verifi get usher britney fml',\n",
       " 'watch telugu movi wat abt u',\n",
       " 'see finish load loan pay',\n",
       " 'hi wk ok hol ye bit run forgot hairdress appoint four need get home n shower beforehand caus prob u \\\\',\n",
       " 'pleas text anymor noth els say',\n",
       " 'okay name ur price long legal wen pick u ave x am xx',\n",
       " 'still look car buy gone drive test yet',\n",
       " 'per request mell mell oru minnaminungint nurungu vettam set callertun caller press copi friend callertun',\n",
       " 'wow right mean guess gave boston men chang search locat nyc someth chang cuz signin page still say boston',\n",
       " 'umma life vava umma love lot dear',\n",
       " 'thank lot wish birthday thank make birthday truli memor',\n",
       " 'aight hit get cash',\n",
       " 'would ip address test consid comput minecraft server',\n",
       " 'know grumpi old peopl mom like better lie alway one play joke',\n",
       " 'dont worri guess busi',\n",
       " 'plural noun research',\n",
       " 'go dinner msg',\n",
       " 'ok wif co like tri new thing scare u dun like mah co u said loud',\n",
       " 'gent tri contact last weekend draw show prize guarante call claim code k valid hr ppm',\n",
       " 'wa ur openin sentenc formal anyway fine juz tt eatin much n puttin weight haha anythin special happen',\n",
       " 'enter cabin pa said happi b day boss felt special askd lunch lunch invit apart went',\n",
       " 'winner u special select receiv holiday flight inc speak live oper claim p min',\n",
       " 'goodo ye must speak friday egg potato ratio tortilla need',\n",
       " 'hmm uncl inform pay school directli pl buy food',\n",
       " 'privat account statement show unredeem bonu point claim call identifi code expir',\n",
       " 'urgent mobil award bonu caller prize final tri contact u call landlin box wr c ppm',\n",
       " 'new address appl pair malarki',\n",
       " 'today voda number end select receiv award match pleas call quot claim code standard rate app',\n",
       " 'go sao mu today done',\n",
       " 'predict wat time _ finish buy',\n",
       " 'good stuff',\n",
       " 'know yetund sent money yet sent text bother send dont involv anyth impos anyth first place apologis',\n",
       " 'room',\n",
       " 'hey girl r u hope u r well del r bak long time c give call sum time lucyxx',\n",
       " 'k k much cost',\n",
       " 'home',\n",
       " 'dear call tmorrow pl accomod',\n",
       " 'first answer question',\n",
       " 'sunshin quiz wkli q win top soni dvd player u know countri algarv txt ansr sp tyron',\n",
       " 'want get laid tonight want real dog locat sent direct ur mob join uk largest dog network bt txting gravel nt ec p msg p',\n",
       " 'haf msn yiju hotmail com',\n",
       " 'call meet',\n",
       " 'check room befor activ',\n",
       " 'rcv msg chat svc free hardcor servic text go u get noth u must age verifi yr network tri',\n",
       " 'got c lazi type forgot _ lect saw pouch like v nice',\n",
       " 'k text way',\n",
       " 'sir wait mail',\n",
       " 'swt thought \\\\nver get tire littl thing lovabl person \\\\ coz somtim littl thing occupi biggest part heart gud ni',\n",
       " 'know pl open back',\n",
       " 'ye see ya dot',\n",
       " 'what staff name take class us',\n",
       " 'freemsg repli text randi sexi femal live local luv hear u netcollex ltd p per msg repli stop end',\n",
       " 'ummma call check life begin qatar pl pray hard',\n",
       " 'k delet contact',\n",
       " 'sindu got job birla soft',\n",
       " 'wine flow never',\n",
       " 'yup thk cine better co need go plaza mah',\n",
       " 'ok ur typic repli',\n",
       " 'per request mell mell oru minnaminungint nurungu vettam set callertun caller press copi friend callertun',\n",
       " 'everywher dirt floor window even shirt sometim open mouth come flow dream world without half chore time joy lot tv show see guess like thing must exist like rain hail mist time done becom one',\n",
       " 'aaooooright work',\n",
       " 'leav hous',\n",
       " 'hello love get interview today happi good boy think miss',\n",
       " 'custom servic annonc new year deliveri wait pleas call arrang deliveri',\n",
       " 'winner u special select receiv cash holiday flight inc speak live oper claim',\n",
       " 'keep safe need miss alreadi envi everyon see real life',\n",
       " 'new car hous parent new job hand',\n",
       " 'love excit day spend make happi',\n",
       " 'pl stop bootydeli f invit friend repli ye see www sm ac u bootydeli stop send stop frnd',\n",
       " 'bangbab ur order way u receiv servic msg download ur content u goto wap bangb tv ur mobil internet servic menu',\n",
       " 'place ur point e cultur modul alreadi',\n",
       " 'urgent tri contact last weekend draw show prize guarante call claim code valid hr',\n",
       " 'hi frnd best way avoid missunderstd wit belov one',\n",
       " 'great escap fanci bridg need lager see tomo',\n",
       " 'ye complet form clark also utter wast',\n",
       " 'sir need axi bank account bank address',\n",
       " 'hmmm thk sure got time hop ard ya go free abt muz call u discuss liao',\n",
       " 'time come later',\n",
       " 'bloodi hell cant believ forgot surnam mr ill give u clue spanish begin',\n",
       " 'well gonna finish bath good fine night',\n",
       " 'let know got money carlo make call',\n",
       " 'u still go mall',\n",
       " 'turn friend stay whole show back til lt gt feel free go ahead smoke lt gt worth',\n",
       " 'text doesnt repli let know log',\n",
       " 'hi spoke maneesha v like know satisfi experi repli toll free ye',\n",
       " 'lift hope offer money need especi end month approach hurt studi anyway gr weekend',\n",
       " 'lol u trust',\n",
       " 'ok gentleman treat digniti respect',\n",
       " 'guy close',\n",
       " 'go noth great bye',\n",
       " 'hello handsom find job lazi work toward get back net mummi boytoy miss',\n",
       " 'haha awesom minut',\n",
       " 'pleas call custom servic repres freephon pm guarante cash prize',\n",
       " 'got xma radio time get',\n",
       " 'ju reach home go bath first si use net tell u finish k',\n",
       " 'uniqu enough find th august www areyouuniqu co uk',\n",
       " 'sorri join leagu peopl dont keep touch mean great deal friend time even great person cost great week',\n",
       " 'hi final complet cours',\n",
       " 'stop howev suggest stay someon abl give or everi stool',\n",
       " 'hope settl new school year wishin gr day',\n",
       " 'gud mrng dear hav nice day',\n",
       " 'u got person stori',\n",
       " 'hamster dead hey tmr meet pm orchard mrt',\n",
       " 'hi kate even hope see tomorrow bit bloodi babyjontet txt back u xxx',\n",
       " 'found enc lt gt',\n",
       " 'sent lt gt buck',\n",
       " 'hello darlin ive finish colleg txt u finish u love kate xxx',\n",
       " 'account refil success inr lt decim gt keralacircl prepaid account balanc rs lt decim gt transact id kr lt gt',\n",
       " 'goodmorn sleep ga',\n",
       " 'u call alter ok',\n",
       " 'say like dat dun buy ericsson oso cannot oredi lar',\n",
       " 'enter cabin pa said happi b day boss felt special askd lunch lunch invit apart went',\n",
       " 'aight yo dat straight dogg',\n",
       " 'pleas give us connect today lt decim gt refund bill',\n",
       " 'shoot big load get readi',\n",
       " 'bruv hope great break reward semest',\n",
       " 'home alway chat',\n",
       " 'k k good studi well',\n",
       " 'yup _ noe leh',\n",
       " 'sound great home',\n",
       " 'final match head toward draw predict',\n",
       " 'tire slept well past night',\n",
       " 'easi ah sen got select mean good',\n",
       " 'take exam march',\n",
       " 'yeah think use gt atm regist sure anyway help let know sure readi',\n",
       " 'ok prob take ur time',\n",
       " 'os call ubandu run without instal hard disk use os copi import file system give repair shop',\n",
       " 'sorri call later',\n",
       " 'u say leh cours noth happen lar say v romant ju bit lor thk e nite sceneri nice leh',\n",
       " 'new mobil must go txt nokia collect today www tc biz optout gbp mtmsg',\n",
       " 'would realli appreci call need someon talk',\n",
       " 'u meet ur dream partner soon ur career flyng start find free txt horo follow ur star sign e g horo ari',\n",
       " 'hey compani elama po mudyadhu',\n",
       " 'life strict teacher bcoz teacher teach lesson amp conduct exam life first conduct exam amp teach lesson happi morn',\n",
       " 'dear good morn',\n",
       " 'get gandhipuram walk cross cut road right side lt gt street road turn first right',\n",
       " 'dear go rubber place',\n",
       " 'sorri batteri die yeah',\n",
       " 'ye tv alway avail work place',\n",
       " 'text meet someon sexi today u find date even flirt u join p repli name age eg sam msg recd thirtyeight penc',\n",
       " 'print oh lt gt come upstair',\n",
       " 'ill littl closer like bu stop street',\n",
       " 'wil reach',\n",
       " 'new theori argument win situat lose person dont argu ur friend kick amp say alway correct',\n",
       " 'u secret admir look make contact u find r reveal think ur special call',\n",
       " 'tomarrow final hear laptop case cant',\n",
       " 'pleassssssseeeee tel v avent done sportsx',\n",
       " 'okay shine meant sign sound better',\n",
       " 'although told u dat baig face watch realli like e watch u gave co fr u thanx everyth dat u done today touch',\n",
       " 'u rememb old commerci',\n",
       " 'late said websit dont slipper',\n",
       " 'ask call ok',\n",
       " 'kalli wont bat nd inning',\n",
       " 'didnt work oh ok goodnight fix readi time wake dearli miss good night sleep',\n",
       " 'congratul ur award cd voucher gift guarante free entri wkli draw txt music tnc www ldew com win ppmx age',\n",
       " 'ranjith cal drpd deeraj deepak min hold',\n",
       " 'wen ur lovabl bcum angri wid u dnt take serious coz angri childish n true way show deep affect care n luv kettoda manda nice day da',\n",
       " '',\n",
       " 'up day also ship compani take wk way usp take week get lag may bribe nipost get stuff',\n",
       " 'back lemm know readi',\n",
       " 'necessarili expect done get back though headin',\n",
       " 'mmm yummi babe nice jolt suzi',\n",
       " 'lover need',\n",
       " 'tri contact repli offer video handset anytim network min unlimit text camcord repli call',\n",
       " 'park next mini come today think',\n",
       " 'yup',\n",
       " 'anyway go shop co si done yet dun disturb u liao',\n",
       " 'luton ring ur around h',\n",
       " 'hey realli horni want chat see nake text hot text charg pm unsubscrib text stop',\n",
       " 'dint come us',\n",
       " 'wana plan trip sometm',\n",
       " 'sure yet still tri get hold',\n",
       " 'ur rington servic chang free credit go club mobil com choos content stop txt club stop p wk club po box mk wt',\n",
       " 'evo download flash jealou',\n",
       " 'rington club get uk singl chart mobil week choos top qualiti rington messag free charg',\n",
       " 'come mu sort narcot situat',\n",
       " 'night end anoth day morn come special way may smile like sunni ray leav worri blue blue bay',\n",
       " 'hmv bonu special pound genuin hmv voucher answer easi question play send hmv info www percent real com',\n",
       " 'usf guess might well take car',\n",
       " 'object bf come',\n",
       " 'thanx',\n",
       " 'tell rob mack gf theater',\n",
       " 'awesom see bit',\n",
       " 'sent type food like',\n",
       " 'done hand celebr full swing yet',\n",
       " 'got call tool',\n",
       " '\\\\wen u miss someon',\n",
       " 'ok ask money far',\n",
       " 'oki',\n",
       " 'yeah think usual guy still pass last night get ahold anybodi let know throw',\n",
       " 'k might come tonight class let earli',\n",
       " 'ok',\n",
       " 'hi babi im cruisin girl friend r u give call hour home that alright fone fone love jenni xxx',\n",
       " 'life mean lot love life love peopl life world call friend call world ge',\n",
       " 'dear shall mail tonit busi street shall updat tonit thing look ok varunnathu edukkukaye raksha ollu good one real sens',\n",
       " 'hey told name gautham ah',\n",
       " 'haf u found feel stupid da v cam work',\n",
       " 'oop got bit',\n",
       " 'much buzi',\n",
       " 'accident delet messag resend pleas',\n",
       " 'mobil custom may claim free camera phone upgrad pay go sim card loyalti call offer end thfeb c appli',\n",
       " 'unless situat go gurl would appropri',\n",
       " 'hurt teas make cri end life die plz keep one rose grave say stupid miss u nice day bslvyl',\n",
       " 'cant pick phone right pl send messag',\n",
       " 'need coffe run tomo believ time week alreadi',\n",
       " 'awesom rememb last time got somebodi high first time diesel v',\n",
       " 'shit realli shock scari cant imagin second def night u think somewher could crash night save taxi',\n",
       " 'oh way food fridg want go meal tonight',\n",
       " 'womdarful actor',\n",
       " 'sm ac blind date u rodd aberdeen unit kingdom check http img sm ac w icmb cktz r blind date send hide',\n",
       " 'yup remb think book',\n",
       " 'jo ask u wana meet',\n",
       " 'lol ye friendship hang thread caus u buy stuff',\n",
       " 'themob check newest select content game tone gossip babe sport keep mobil fit funki text wap',\n",
       " 'garag key bookshelf',\n",
       " 'today accept day u accept brother sister lover dear best clo lvblefrnd jstfrnd cutefrnd lifpartnr belovd swtheart bstfrnd rpli mean enemi',\n",
       " 'think ur smart win week weekli quiz text play cs winnersclub po box uz gbp week',\n",
       " 'say give call friend got money definit buy end week',\n",
       " 'hi way u day normal way real ur uniqu hope know u rest mylif hope u find wot lost',\n",
       " 'made day great day',\n",
       " 'k k advanc happi pongal',\n",
       " 'hmmm guess go kb n power yoga haha dunno tahan power yoga anot thk got lo oso forgot liao',\n",
       " 'realli dude friend afraid',\n",
       " 'decemb mobil mth entitl updat latest colour camera mobil free call mobil updat co free',\n",
       " 'coffe cake guess',\n",
       " 'merri christma babe love ya kiss',\n",
       " 'hey dont go watch x men lunch haha',\n",
       " 'cud u tell ppl im gona b bit l co buse hav gon past co full im still waitin pete x',\n",
       " 'would great guild could meet bristol road somewher get touch weekend plan take flight good week',\n",
       " 'problem',\n",
       " 'call messag miss call',\n",
       " 'hi da today class',\n",
       " 'say good sign well know track record read women',\n",
       " 'cool text park',\n",
       " 'read text sent meant joke read light',\n",
       " 'k k apo k good movi',\n",
       " 'mayb could get book tomo return immedi someth',\n",
       " 'call germani penc per minut call fix line via access number prepay direct access',\n",
       " 'chanc might evapor soon violat privaci steal phone number employ paperwork cool pleas contact report supervisor',\n",
       " 'valentin day special win quiz take partner trip lifetim send go p msg rcvd custcar',\n",
       " 'ta daaaaa home babe still',\n",
       " 'cool come havent wine dine',\n",
       " 'sleep surf',\n",
       " 'sorri call later',\n",
       " 'u call right call hand phone',\n",
       " 'ok great thanx lot',\n",
       " 'take post come must text happi read one wiv hello carolin end favourit bless',\n",
       " 'u hide stranger',\n",
       " 'interest like',\n",
       " 'sister clear two round birla soft yesterday',\n",
       " 'gudnit tc practic go',\n",
       " 'di yiju ju saw ur mail case huim havent sent u num di num',\n",
       " 'one small prestig problem',\n",
       " 'fanci shag interest sextextuk com txt xxuk suzi txt cost per msg tnc websit x',\n",
       " 'check realli miss see jeremiah great month',\n",
       " 'nah help never iphon',\n",
       " 'car hour half go apeshit',\n",
       " 'today sorri day ever angri ever misbehav hurt plz plz slap urself bcoz ur fault basic good',\n",
       " 'yo guy ever figur much need alcohol jay tri figur much safe spend weed',\n",
       " 'lt gt ish minut minut ago wtf',\n",
       " 'thank call forgot say happi onam sirji fine rememb met insur person meet qatar insha allah rakhesh ex tata aig join tissco tayseer',\n",
       " 'congratul ur award cd voucher gift guarante free entri wkli draw txt music tnc www ldew com win ppmx age',\n",
       " 'ur cash balanc current pound maxim ur cash send cash p msg cc hg suit land row w j hl',\n",
       " 'actor work work even sleep late sinc unemploy moment alway sleep late unemploy everi day saturday',\n",
       " 'hello got st andrew boy long way cold keep post',\n",
       " 'ha ha cool cool chikku chikku db',\n",
       " 'oh ok prob',\n",
       " 'check audrey statu right',\n",
       " 'busi tri finish new year look forward final meet',\n",
       " 'good afternoon sunshin dawn day refresh happi aliv breath air smile think love alway',\n",
       " 'well know z take care worri',\n",
       " 'update_now xma offer latest motorola sonyericsson nokia free bluetooth doubl min txt orang call mobileupd call optout f q',\n",
       " 'discount code rp stop messag repli stop www regalportfolio co uk custom servic',\n",
       " 'wat uniform get',\n",
       " 'cool text readi',\n",
       " 'hello boytoy geeee miss alreadi woke wish bed cuddl love',\n",
       " 'spoil bed well',\n",
       " 'go bath msg next lt gt min',\n",
       " 'cant keep talk peopl sure pay agre price pl tell want realli buy much will pay',\n",
       " 'thank rington order refer charg gbp per week unsubscrib anytim call custom servic',\n",
       " 'say happen',\n",
       " 'could seen recognis face',\n",
       " 'well lot thing happen lindsay new year sigh bar ptbo blue heron someth go',\n",
       " 'keep payasam rinu bring',\n",
       " 'taught ranjith sir call sm like becau he verifi project prabu told today pa dont mistak',\n",
       " 'guess worri must know way bodi repair quit sure worri take slow first test guid ovul relax noth said reason worri keep followin',\n",
       " 'yeah sure give coupl minut track wallet',\n",
       " 'hey leav big deal take care',\n",
       " 'hey late ah meet',\n",
       " 'doubl min txt month free bluetooth orang avail soni nokia motorola phone call mobileupd call optout n dx',\n",
       " 'took mr owl lick',\n",
       " 'custom place call',\n",
       " 'mm time dont like fun',\n",
       " 'mth half price orang line rental latest camera phone free phone mth call mobilesdirect free updat stoptxt',\n",
       " 'yup lunch buffet u eat alreadi',\n",
       " 'huh late fr dinner',\n",
       " 'hey sat go intro pilat kickbox',\n",
       " 'morn ok',\n",
       " 'ye think offic lap room think that last day didnt shut',\n",
       " 'pick bout ish time go',\n",
       " 'perform award calcul everi two month current one month period',\n",
       " 'actual sleep still might u call back text gr rock si send u text wen wake',\n",
       " 'alway put busi put pictur ass facebook one open peopl ever met would think pictur room would hurt make feel violat',\n",
       " 'good even sir al salam wahleykkum share happi news grace god got offer tayseer tissco join hope fine inshah allah meet sometim rakhesh visitor india',\n",
       " 'hmmm k want chang field quickli da wanna get system administr network administr',\n",
       " 'free rington text first poli text get true tone help st free tone x pw e nd txt stop',\n",
       " 'dear chechi talk',\n",
       " 'hair cream ship',\n",
       " 'none happen til get though',\n",
       " 'yep great loxahatche xma tree burn lt gt start hour',\n",
       " 'haha get use drive usf man know lot stoner',\n",
       " 'well slightli disastr class pm fav darl hope day ok coffe wld good stay late tomorrow time place alway',\n",
       " 'hello good week fanci drink someth later',\n",
       " 'headin toward busetop',\n",
       " 'messag text miss sender name miss number miss sent date miss miss u lot that everyth miss sent via fullonsm com',\n",
       " 'come room point iron plan weekend',\n",
       " 'co want thing',\n",
       " 'oki go yan jiu skip ard oso go cine den go mrt one blah blah blah',\n",
       " 'bring home wendi',\n",
       " 'date servic cal l box sk ch',\n",
       " 'whatsup dont u want sleep',\n",
       " 'alright new goal',\n",
       " 'free entri weekli competit text word win c www txttowin co uk',\n",
       " 'alright head minut text meet',\n",
       " 'send logo ur lover name join heart txt love name name mobno eg love adam eve yahoo pobox w wq txtno ad p',\n",
       " 'ye last week take live call',\n",
       " 'someon contact date servic enter phone fanci find call landlin pobox n tf p',\n",
       " 'siva hostel aha',\n",
       " 'urgent mobil number award prize guarante call land line claim valid hr',\n",
       " 'send ur friend receiv someth ur voic speak express childish naughti sentiment rowdi ful attitud romant shi attract funni lt gt irrit lt gt lovabl repli',\n",
       " 'ok ok guess',\n",
       " 'aathi dear',\n",
       " 'pain urin thing els',\n",
       " 'esplanad _ mind give lift co got car today',\n",
       " 'wnt buy bmw car urgent vri urgent hv shortag lt gt lac sourc arng di amt lt gt lac that prob',\n",
       " 'home watch tv lor',\n",
       " 'usual take fifteen fuck minut respond ye question',\n",
       " 'congrat nokia video camera phone call call cost ppm ave call min vari mobil close post bcm ldn wc n xx',\n",
       " 'book ticket pongal',\n",
       " 'avail like right around hillsborough amp lt gt th',\n",
       " 'messag sent askin lt gt dollar shoul pay lt gt lt gt',\n",
       " 'ask g iouri told stori like ten time alreadi',\n",
       " 'long applebe fuck take',\n",
       " 'hi hope u get txt journey hasnt gd min late think',\n",
       " 'like love arrang',\n",
       " 'ye realli great bhaji told kalli best cricket sachin world tough get',\n",
       " 'suppos wake gt',\n",
       " 'oic saw tot din c found group liao',\n",
       " 'sorri call later',\n",
       " '\\\\hey hey wereth monkeespeopl say monkeyaround howdi gorgeou',\n",
       " 'sorri batteri die come get gram place',\n",
       " 'well done blimey exercis yeah kinda rememb wot hmm',\n",
       " 'wont get concentr dear know mind everyth',\n",
       " 'lol made plan new year',\n",
       " 'min later k',\n",
       " 'hank lotsli',\n",
       " 'thank hope good day today',\n",
       " 'k k detail want transfer acc enough',\n",
       " 'ok tell stay yeah tough optimist thing improv month',\n",
       " 'loan purpos homeown tenant welcom previous refus still help call free text back help',\n",
       " 'si si think ill go make oreo truffl',\n",
       " 'look ami ure beauti intellig woman like u lot know u like like worri',\n",
       " 'hope result consist intellig kind start ask practicum link keep ear open best ttyl',\n",
       " 'call cost guess isnt bad miss ya need ya want ya love ya',\n",
       " 'go thru differ feel waver decis cope individu time heal everyth believ',\n",
       " 'u go phone gonna die stay',\n",
       " 'great never better day give even reason thank god',\n",
       " 'upgrdcentr orang custom may claim free camera phone upgrad loyalti call offer end th juli c appli opt avail',\n",
       " 'sorri call later ok bye',\n",
       " 'ok way railway',\n",
       " 'great princess love give receiv oral doggi style fave posit enjoy make love lt gt time per night',\n",
       " 'put stuff road keep get slipperi',\n",
       " 'go ride bike',\n",
       " 'yup need ju wait e rain stop',\n",
       " 'mani compani tell languag',\n",
       " 'okmail dear dave final notic collect tenerif holiday cash award call landlin tc sae box cw wx ppm',\n",
       " 'long sinc scream princess',\n",
       " 'noth meant money enter account bank remov flat rate someon transfer lt gt account lt gt dollar got remov bank differ charg also differ sure trust ja person send account detail co',\n",
       " 'want get laid tonight want real dog locat sent direct ur mob join uk largest dog network txting moan nyt ec p msg p',\n",
       " 'nice line said broken heart plz cum time infront wise trust u good',\n",
       " 'ok gonna head usf like fifteen minut',\n",
       " 'love aathi love u lot',\n",
       " 'tension ah machi problem',\n",
       " 'k pick anoth th done',\n",
       " 'guy get back g said think stay mcr',\n",
       " 'almost see u sec',\n",
       " 'yo carlo friend alreadi ask work weekend',\n",
       " 'watch tv lor',\n",
       " 'thank babi cant wait tast real thing',\n",
       " 'chang fb jaykwon thuglyf falconerf',\n",
       " 'win realli side long time',\n",
       " 'free messag activ free text messag repli messag word free term condit visit www com',\n",
       " 'dear reach railway happen',\n",
       " 'depend qualiti want type sent boy fade glori want ralph mayb',\n",
       " 'think fix send test messag',\n",
       " 'sorri man account dri would want could trade back half could buy shit credit card',\n",
       " 'congrat year special cinema pass call c suprman v matrix starwar etc free bx ip pm dont miss',\n",
       " 'sorri meet call later',\n",
       " 'class lt gt reunion',\n",
       " 'free call',\n",
       " 'got meh',\n",
       " 'nope think go monday sorri repli late',\n",
       " 'told accentur confirm true',\n",
       " 'kate jackson rec center ish right',\n",
       " 'dear reach room',\n",
       " 'fight world easi u either win lose bt fightng close u dificult u lose u lose u win u still lose',\n",
       " '_ come',\n",
       " 'check nuerologist',\n",
       " 'lolnic went fish water',\n",
       " 'congratul week competit draw u prize claim call b cs stop sm ppm',\n",
       " 'wait e car dat bore wat co wait outsid got noth home stuff watch tv wat',\n",
       " 'mayb westshor hyde park villag place near hous',\n",
       " 'know anthoni bring money school fee pay rent stuff like that need help friend need',\n",
       " 'signific',\n",
       " 'opinion jada kusruthi lovabl silent spl charact matur stylish simpl pl repli',\n",
       " 'latest g still scroung ammo want give new ak tri',\n",
       " 'prabha soryda reali frm heart sori',\n",
       " 'lol ok forgiven',\n",
       " 'jst chang tat',\n",
       " 'guarante latest nokia phone gb ipod mp player prize txt word collect ibhltd ldnw h p mtmsgrcvd',\n",
       " 'competit',\n",
       " 'boltblu tone p repli poli mono eg poli cha cha slide yeah slow jamz toxic come stop tone txt',\n",
       " 'credit top http www bubbletext com renew pin tgxxrz',\n",
       " 'way transport less problemat sat night way u want ask n join bday feel free need know definit no book fri',\n",
       " 'usual person unconsci children adult may behav abnorm call',\n",
       " 'ebay might less elsewher',\n",
       " 'shall come get pickl',\n",
       " 'gonna go get taco',\n",
       " 'rude campu',\n",
       " 'urgent mobil award bonu caller prize nd attempt contact call box qu',\n",
       " 'hi b ard christma enjoy n merri x ma',\n",
       " 'today offer claim ur worth discount voucher text ye savamob member offer mobil cs sub unsub repli x',\n",
       " 'ye pretti ladi like singl',\n",
       " 'reciev tone within next hr term condit pleas see channel u teletext pg',\n",
       " 'jay say doubl faggot',\n",
       " 'privat account statement show un redeem point call identifi code expir',\n",
       " 'today sunday sunday holiday work',\n",
       " 'gudnit tc practic go',\n",
       " 'late',\n",
       " 'call hope l r malaria know miss guy miss bani big pl give love especi great day',\n",
       " 'good afternoon love goe day hope mayb got lead job think boytoy send passion kiss across sea',\n",
       " 'probabl gonna see later tonight lt',\n",
       " 'mayb fat finger press button know',\n",
       " 'ummmmmaah mani mani happi return day dear sweet heart happi birthday dear',\n",
       " 'tirupur da start offic call',\n",
       " 'www applausestor com monthlysubscript p msg max month csc web age stop txt stop',\n",
       " 'famou quot develop abil listen anyth uncondit without lose temper self confid mean marri',\n",
       " 'go colleg pa els ill come self pa',\n",
       " 'oclock mine bash flat plan',\n",
       " 'girl stay bed girl need recoveri time id rather pass fun coop bed',\n",
       " 'special',\n",
       " 'know need get hotel got invit apologis cali sweet come english bloke weddin',\n",
       " 'sorri took long omw',\n",
       " 'wait lt gt min',\n",
       " 'ok give minut think see btw alibi cut hair whole time',\n",
       " 'imagin final get sink bath put pace mayb even eat left also imagin feel cage cock surround bath water remind alway own enjoy cuck',\n",
       " 'hurri weed defici like three day',\n",
       " 'sure get acknowledg astoundingli tactless gener faggi demand blood oath fo',\n",
       " 'ok everi night take warm bath drink cup milk see work magic still need loos weight know',\n",
       " 'look fri pan case cheap book perhap silli fri pan like book',\n",
       " 'well uv caus mutat sunscreen like essenti theseday',\n",
       " 'lunch onlin',\n",
       " 'know friend alreadi told',\n",
       " 'hi princess thank pic pretti',\n",
       " 'aiyo u alway c ex one dunno abt mei repli first time u repli fast lucki workin huh got bao ur sugardad ah gee',\n",
       " 'hi msg offic',\n",
       " 'thanx e browni v nice',\n",
       " 'geeeee love much bare stand',\n",
       " 'gent tri contact last weekend draw show prize guarante call claim code k valid hr ppm',\n",
       " 'fuck babe miss alreadi know let send money toward net need want crave',\n",
       " 'ill call u mrw ninish address icki american freek wont stop callin bad jen k eh',\n",
       " 'oooh bed ridden ey think',\n",
       " 'anyway go gym whatev love smile hope ok good day babe miss much alreadi',\n",
       " 'love daddi make scream pleasur go slap ass dick',\n",
       " 'wot u wanna missi',\n",
       " 'yar lor wait mum finish sch lunch lor whole morn stay home clean room room quit clean hee',\n",
       " 'know lab goggl went',\n",
       " 'open door',\n",
       " 'wait call',\n",
       " 'nope wait sch daddi',\n",
       " 'cash prize claim call',\n",
       " 'tire argu week week want',\n",
       " 'wait sch finish ard',\n",
       " 'mobil number claim call us back ring claim hot line',\n",
       " 'arngd marriag u r walkin unfortuntli snake bite u bt love marriag danc frnt snake amp sayin bite bite',\n",
       " 'huh earli _ dinner outsid izzit',\n",
       " 'ok anyway need chang said',\n",
       " 'tri contact repli offer min textand new video phone call repli free deliveri tomorrow',\n",
       " 'ex wife abl kid want kid one day',\n",
       " 'scotland hope show jjc tendenc take care live dream',\n",
       " 'tell u headach want use hour sick time',\n",
       " 'dun thk quit yet hmmm go jazz yogasana oso go meet em lesson den',\n",
       " '\\\\pete pleas ring meiv hardli gotani credit\\\\',\n",
       " 'ya srsli better yi tho',\n",
       " 'meet call later',\n",
       " 'ur chanc win wkli shop spree txt shop c www txt shop com custcar x p wk',\n",
       " 'special select receiv pound award call line close cost ppm cs appli ag promo',\n",
       " 'privat account statement show un redeem point call identifi code expir',\n",
       " 'still grand prix',\n",
       " 'met stranger choos friend long world stand friendship never end let friend forev gud nitz',\n",
       " 'great',\n",
       " 'gud mrng dear nice day',\n",
       " 'import custom servic announc call freephon',\n",
       " 'exhaust train morn much wine pie sleep well',\n",
       " 'go buy mum present ar',\n",
       " 'mind blastin tsunami occur rajnik stop swim indian ocean',\n",
       " 'u send home first ok lor readi yet',\n",
       " 'speak cash yet',\n",
       " 'happi come noon',\n",
       " 'meet lunch la',\n",
       " 'take care n get well soon',\n",
       " 'xclusiv clubsaisai morow soire special zouk nichol pari free rose ladi info',\n",
       " 'meant say cant wait see u get bore bridgwat banter',\n",
       " 'neva mind ok',\n",
       " 'fine imma get drink somethin want come find',\n",
       " 'day kick euro u kept date latest news result daili remov send get txt stop',\n",
       " 'valentin game send di msg ur friend answer r someon realli love u que colour suit best rpli',\n",
       " 'mani depend',\n",
       " 'thanx today cer nice catch ave find time often oh well take care c u soon c',\n",
       " 'call said choos futur',\n",
       " '\\\\happi valentin day\\\\ know earli hundr handsom beauti wish thought finish aunti uncl st',\n",
       " 'like v shock leh co tell shuhui like tell leona also like dat almost know liao got ask abt ur reaction lor',\n",
       " 'famili happi',\n",
       " 'come n pick _ come immedi aft ur lesson',\n",
       " 'let snow let snow kind weather bring ppl togeth friendship grow',\n",
       " 'dear got lt gt dollar hi hi',\n",
       " 'good word word may leav u dismay mani time',\n",
       " 'make sure alex know birthday fifteen minut far concern',\n",
       " 'sorri got thing may pub later',\n",
       " 'nah straight bring bud drink someth actual littl use straight cash',\n",
       " 'haha good hear offici paid market th',\n",
       " 'mani lick take get center tootsi pop',\n",
       " 'yup thk r e teacher said make face look longer darren ask cut short',\n",
       " 'new textbuddi chat horni guy ur area p free receiv search postcod gaytextbuddi com txt one name',\n",
       " 'today vodafon number end select receiv award number match call receiv award',\n",
       " 'pleas dont say like hi hi hi',\n",
       " 'thank u',\n",
       " 'oh forward messag thought send',\n",
       " 'got seventeen pound seven hundr ml hope ok',\n",
       " 'dear voucher holder claim week offer pc go http www e tlp co uk expressoff ts cs appli stop text txt stop',\n",
       " 'n funni',\n",
       " 'sweetheart hope kind day one load reason smile biola',\n",
       " '_ login dat time dad fetch _ home',\n",
       " 'shower babi',\n",
       " 'askd u question hour answer',\n",
       " 'well imma definit need restock thanksgiv let know',\n",
       " 'said kiss kiss sound effect gorgeou man kind person need smile brighten day',\n",
       " 'probabl gonna swing wee bit',\n",
       " 'ya nice readi thursday',\n",
       " 'allo brave buse taken train triumph mean b ham jolli good rest week',\n",
       " 'watch cartoon listen music amp eve go templ amp church u',\n",
       " 'mind ask happen dont say uncomfort',\n",
       " 'privat account statement show un redeem point call identifi code expir',\n",
       " 'prob send email',\n",
       " 'cash prize claim call c rstm sw ss ppm',\n",
       " 'that cool sometim slow gentl sonetim rough hard',\n",
       " 'gonna say sorri would normal start panic time sorri see tuesday',\n",
       " 'wait know wesley town bet hella drug',\n",
       " 'fine miss much',\n",
       " 'u got person stori',\n",
       " 'tell drug dealer get impati',\n",
       " 'sun cant come earth send luv ray cloud cant come river send luv rain cant come meet u send care msg u gud evng',\n",
       " 'place man',\n",
       " 'doesnt make sens take unless free need know wikipedia com',\n",
       " 'premium phone servic call',\n",
       " 'sea lay rock rock envelop envelop paper paper word',\n",
       " 'mum repent',\n",
       " 'sorri go home first daddi come fetch _ later',\n",
       " 'leav de start prepar next',\n",
       " 'ye babi studi posit kama sutra',\n",
       " 'en chikku nang bakra msg kalstiya tea coffe',\n",
       " 'carlo minut still need buy',\n",
       " 'pay lt decim gt lakh',\n",
       " 'good even ttyl',\n",
       " 'u receiv msg',\n",
       " 'ho ho big belli laugh see ya tomo',\n",
       " 'sm ac sun post hello \\\\you seem cool',\n",
       " 'get ur st rington free repli msg tone gr top tone phone everi week per wk opt send stop',\n",
       " 'ditto worri say anyth anymor like said last night whatev want peac',\n",
       " 'got lt gt way could pick',\n",
       " 'dont knw pa drink milk',\n",
       " 'mayb say hi find got card great escap wetherspoon',\n",
       " 'piggi r u awak bet u still sleep go lunch',\n",
       " 'caus freaki lol',\n",
       " 'miss call caus yell scrappi miss u wait u come home lone today',\n",
       " 'hex place talk explain',\n",
       " 'log wat sdryb',\n",
       " 'xy go e lunch',\n",
       " 'hi sue year old work lapdanc love sex text live bedroom text sue textoper g da ppmsg',\n",
       " 'want ask _ wait finish lect co lect finish hour anyway',\n",
       " 'finish work yet',\n",
       " 'everi king cri babi everi great build map imprtant u r today u wil reach tomorw gud ni',\n",
       " 'dear cherthala case u r come cochin pl call bfore u start shall also reach accordingli tell day u r come tmorow engag an holiday',\n",
       " 'thank love torch bold',\n",
       " 'forward pleas call immedi urgent messag wait',\n",
       " 'farm open',\n",
       " 'sorri troubl u buy dad big small sat n sun thanx',\n",
       " 'sister law hope great month say hey abiola',\n",
       " 'purchas stuff today mail po box number',\n",
       " 'ah poop look like ill prob send laptop get fix cuz gpu problem',\n",
       " 'good good job like entrepreneur',\n",
       " 'aight close still around alex place',\n",
       " 'meet corpor st outsid gap _ see mind work',\n",
       " 'mum ask _ buy food home',\n",
       " 'k u also dont msg repli msg',\n",
       " 'much r _ will pay',\n",
       " 'sorri call later',\n",
       " 'import prevent dehydr give enough fluid',\n",
       " 'that bit weird even suppos happen good idea sure pub',\n",
       " 'true dear sat pray even felt sm time',\n",
       " 'think get away trek long famili town sorri',\n",
       " 'wanna gym harri',\n",
       " 'quit late lar ard anyway wun b drivin',\n",
       " 'review keep fantast nokia n gage game deck club nokia go www cnupdat com newslett unsubscrib alert repli word',\n",
       " 'mth half price orang line rental latest camera phone free phone mth call mobilesdirect free updat stoptxt cs',\n",
       " 'height confid aeronaut professor wer calld amp wer askd sit aeroplan aftr sat wer told dat plane ws made student dey hurri plane bt didnt move said \\\\if made student',\n",
       " 'seem like weird time night g want come smoke day shitstorm attribut alway come make everyon smoke',\n",
       " 'pm cost p',\n",
       " 'save stress person dorm account send account detail money sent',\n",
       " 'also know lunch menu da know',\n",
       " 'stuff sell tell',\n",
       " 'urgent nd attempt contact u u call b csbcm wc n xx callcost ppm mobilesvari max',\n",
       " 'book lesson msg call work sth go get spec membership px',\n",
       " 'guarante cash prize claim yr prize call custom servic repres pm',\n",
       " 'macha dont feel upset assum mindset believ one even wonder plan us let life begin call anytim',\n",
       " 'oh send address',\n",
       " 'fine anytim best',\n",
       " 'wondar full flim',\n",
       " 'ya even cooki jelli',\n",
       " 'world run still mayb feel admit mad correct let call life keep run world may u r also run let run',\n",
       " 'got look scrumptiou daddi want eat night long',\n",
       " 'co lar ba dao ok pm lor u never ask go ah said u would ask fri said u ask today',\n",
       " 'alright omw gotta chang order half th',\n",
       " 'exactli anyway far jide studi visit',\n",
       " 'dunno u ask',\n",
       " 'email alertfrom jeri stewarts kbsubject low cost prescripiton drvgsto listen email call',\n",
       " 'spring come earli yay',\n",
       " 'lol feel bad use money take steak dinner',\n",
       " 'even u dont get troubl convinc tel twice tel neglect msg dont c read dont repli',\n",
       " 'leav qatar tonit search opportun went fast pl add ur prayer dear rakhesh',\n",
       " 'one talk',\n",
       " 'thank look realli appreci',\n",
       " 'hi custom loyalti offer new nokia mobil txtauction txt word start get ctxt tc p mtmsg',\n",
       " 'wish',\n",
       " 'haha mayb u rite u know well da feel like someon gd lor u faster go find one gal group attach liao',\n",
       " 'ye glad made',\n",
       " 'well littl time thing good time ahead',\n",
       " 'got room soon _ put clock back til shout everyon get realis wahay anoth hour bed',\n",
       " 'ok may free gym',\n",
       " 'men like shorter ladi gaze eye',\n",
       " 'dunno ju say go lido time',\n",
       " 'promis take good care princess run pleas send pic get chanc ttyl',\n",
       " 'u subscrib best mobil content servic uk per day send stop helplin',\n",
       " 'reason spoken year anyway great week best exam',\n",
       " 'monday next week give full gist',\n",
       " 'realiz year thousand old ladi run around tattoo',\n",
       " 'import custom servic announc premier',\n",
       " 'dont gimm lip caveboy',\n",
       " 'get librari',\n",
       " 'reali sorri recognis number confus r u pleas',\n",
       " 'didnt holla',\n",
       " 'cant think anyon spare room top head',\n",
       " 'faith make thing possibl hope make thing work love make thing beauti may three christma merri christma',\n",
       " 'u made appoint',\n",
       " 'call carlo phone vibrat act might hear text',\n",
       " 'romant pari night flight book next year call ts cs appli',\n",
       " 'grandma oh dear u still ill felt shit morn think hungov anoth night leav sat',\n",
       " 'urgent ur guarante award still unclaim call closingd claimcod pmmorefrommobil bremov mobypobox ls yf',\n",
       " 'noth ju tot u would ask co u ba gua went mt faber yest yest ju went alreadi mah today go ju call lor',\n",
       " 'wish famili merri \\\\x\\\\ ma happi new year advanc',\n",
       " 'ur award citi break could win summer shop spree everi wk txt store skilgm tsc winawk age perwksub',\n",
       " 'nt goin got somethin unless meetin dinner lor haha wonder go ti time',\n",
       " 'sorri call later',\n",
       " 'cant pick phone right pl send messag',\n",
       " 'lol know dramat school alreadi close tomorrow appar drive inch snow suppos get',\n",
       " 'get anywher damn job hunt',\n",
       " 'lol u drunkard hair moment yeah still tonight wat plan',\n",
       " 'idc get weasel way shit twice row',\n",
       " 'wil lt gt minut got space',\n",
       " 'sleep surf',\n",
       " 'thank pick trash',\n",
       " 'go tell friend sure want live smoke much spend hour beg come smoke',\n",
       " '\\\\hi kate love see tonight ill phone tomorrow got sing guy gave card xxx\\\\',\n",
       " 'happi new year dear brother realli miss got number decid send text wish happi abiola',\n",
       " 'mean get door',\n",
       " 'opinion jada kusruthi lovabl silent spl charact matur stylish simpl pl repli',\n",
       " 'hmmm thought said hour slave late punish',\n",
       " 'beerag',\n",
       " 'import custom servic announc premier call freephon',\n",
       " 'dont think turn like randomlli within min open',\n",
       " 'suppos make still town though',\n",
       " 'time fix spell sometim get complet diff word go figur',\n",
       " 'ever thought live good life perfect partner txt back name age join mobil commun p sm',\n",
       " 'free top polyphon tone call nation rate get toppoli tune sent everi week text subpoli per pole unsub',\n",
       " 'gud mrng dear hav nice day',\n",
       " 'hope enjoy game yesterday sorri touch pl know fondli bein thot great week abiola',\n",
       " 'e best ur drive tmr',\n",
       " 'u dogbreath sound like jan c al',\n",
       " 'omg want scream weigh lost weight woohoo',\n",
       " 'gener one uncount noun u dictionari piec research',\n",
       " 'realli get hang around',\n",
       " 'orang custom may claim free camera phone upgrad loyalti call offer end thmarch c appli opt availa',\n",
       " '\\\\petey boy wherear friendsar thekingshead come canlov nic\\\\',\n",
       " 'ok msg u b leav hous',\n",
       " '\\\\gimm few\\\\ lt gt minut ago',\n",
       " 'last chanc claim ur worth discount voucher today text shop savamob offer mobil cs savamob pobox uz sub',\n",
       " 'appt lt time gt fault u listen told u twice',\n",
       " 'free st week nokia tone ur mobil everi week txt nokia get txting tell ur mate www getz co uk pobox w wq norm p tone',\n",
       " 'guarante award even cashto claim ur award call free stop getstop php rg jx',\n",
       " 'k',\n",
       " 'dled imp',\n",
       " 'sure make sure know smokin yet',\n",
       " 'boooo alway work quit',\n",
       " 'take half day leav bec well',\n",
       " 'ugh wanna get bed warm',\n",
       " 'nervou lt gt',\n",
       " 'ring come guy costum gift futur yowif hint hint',\n",
       " 'congratul ur award either cd gift voucher free entri weekli draw txt music tnc www ldew com win ppmx age',\n",
       " 'borrow ur bag ok',\n",
       " 'u outbid simonwatson shinco dvd plyr bid visit sm ac smsreward end bid notif repli end',\n",
       " 'boytoy miss happen',\n",
       " 'lot use one babe model help youi bring match',\n",
       " 'also bring galileo dobbi',\n",
       " 'respond',\n",
       " '\\\\boo babe u enjoyin yourjob u seem b gettin well hunni hope ure ok take care llspeak u soonlot lovem xxxx \\\\',\n",
       " 'good afternoon starshin boytoy crave yet ach fuck sip cappuccino miss babe teas kiss',\n",
       " 'road cant txt',\n",
       " 'smsservic yourinclus text credit pl goto www comuk net login qxj unsubscrib stop extra charg help comuk cm ae',\n",
       " 'p alfi moon children need song ur mob tell ur txt tone chariti nokia poli chariti poli zed profit chariti',\n",
       " 'good even ttyl',\n",
       " 'hmm bit piec lol sigh',\n",
       " 'hahaha use brain dear',\n",
       " 'hey got mail',\n",
       " 'sorri light turn green meant anoth friend want lt gt worth may around',\n",
       " 'thank yesterday sir wonder hope enjoy burial mojibiola',\n",
       " 'u secret admir reveal think u r special call opt repli reveal stop per msg recd cust care',\n",
       " 'hi mate rv u hav nice hol messag say hello coz sent u age start drive stay road rvx',\n",
       " 'dear voucher holder claim week offer pc pleas go http www e tlp co uk expressoff ts cs appli stop text txt stop',\n",
       " 'thank much skype wit kz sura didnt get pleasur compani hope good given ultimatum oh countin aburo enjoy messag sent day ago',\n",
       " 'sure result offer',\n",
       " 'good morn dear great amp success day',\n",
       " 'want anytim network min text new video phone five pound per week call repli deliveri tomorrow',\n",
       " 'sir late pay rent past month pay lt gt charg felt would inconsider nag someth give great cost didnt speak howev recess wont abl pay charg month henc askin well ahead month end pleas help thank',\n",
       " 'tri contact offer new video phone anytim network min half price rental camcord call repli deliveri wed',\n",
       " 'last chanc claim ur worth discount voucher text ye savamob member offer mobil cs sub remov txt x stop',\n",
       " 'luv u soo much u understand special u r ring u morrow luv u xxx',\n",
       " 'pl send comprehens mail pay much',\n",
       " 'prashanthettan mother pass away last night pray famili',\n",
       " 'urgent call landlin complimentari ibiza holiday cash await collect sae cs po box sk wp ppm',\n",
       " 'k k go',\n",
       " 'meanwhil shit suit xavier decid give us lt gt second warn samantha come play jay guitar impress shit also think doug realiz live anymor',\n",
       " 'stomach thru much trauma swear eat better lose weight',\n",
       " 'offic what matter msg call break',\n",
       " 'yeah bare enough room two us x mani fuck shoe sorri man see later',\n",
       " 'today offer claim ur worth discount voucher text ye savamob member offer mobil cs sub unsub repli x',\n",
       " 'u reach orchard alreadi u wan go buy ticket first',\n",
       " 'real babi want bring inner tigress',\n",
       " 'da run activ full version da',\n",
       " '\\\\ah poor babi hope urfeel bettersn luv probthat overdos work hey go care spk u sn lot lovejen xxx \\\\',\n",
       " 'stop stori told return say order',\n",
       " 'talk sexi make new friend fall love world discreet text date servic text vip see could meet',\n",
       " 'go take babe',\n",
       " 'hai ana tomarrow come morn lt decim gt ill sathi go rto offic repli came home',\n",
       " 'spoon okay',\n",
       " 'say somebodi name tampa',\n",
       " 'work go min',\n",
       " 'brother geniu',\n",
       " 'sorri guess whenev get hold connect mayb hour two text',\n",
       " 'u find time bu coz need sort stuff',\n",
       " 'dude ive see lotta corvett late',\n",
       " 'congratul ur award either yr suppli cd virgin record mysteri gift guarante call ts cs www smsco net pm approx min',\n",
       " 'consid wall bunker shit import never play peac guess place high enough matter',\n",
       " 'privat account statement xxxxxx show un redeem point call identifi code expir',\n",
       " 'hello need posh bird chap user trial prod champney put need address dob asap ta r',\n",
       " 'u want xma free text messag new video phone half price line rental call free find',\n",
       " 'well offici philosoph hole u wanna call home readi save',\n",
       " 'go good problem still need littl experi understand american custom voic',\n",
       " 'text drop x',\n",
       " 'ugh long day exhaust want cuddl take nap',\n",
       " 'talk atleast day otherwis miss best friend world shakespear shesil lt gt',\n",
       " 'shop till u drop either k k cash travel voucher call ntt po box cr bt fixedlin cost ppm mobil vari',\n",
       " 'castor need see someth',\n",
       " 'sunshin quiz wkli q win top soni dvd player u know countri liverpool play mid week txt ansr sp tyron',\n",
       " 'u secret admir look make contact u find r reveal think ur special call',\n",
       " 'u secret admir look make contact u find r reveal think ur special call stopsm',\n",
       " 'remind download content alreadi paid goto http doit mymobi tv collect content',\n",
       " 'see knew give break time woul lead alway want miss curfew gonna gibe til one midnight movi gonna get til need come home need getsleep anyth need b studdi ear train',\n",
       " 'love give massag use lot babi oil fave posit',\n",
       " 'dude go sup',\n",
       " 'yoyyooo u know chang permiss drive mac usb flash drive',\n",
       " 'gibb unsold mike hussey',\n",
       " 'like talk pa abl dont know',\n",
       " 'dun cut short leh u dun like ah fail quit sad',\n",
       " 'unbeliev faglord',\n",
       " 'wife knew time murder exactli',\n",
       " 'ask princess',\n",
       " 'great princess think',\n",
       " 'nutter cutter ctter cttergg cttargg ctargg ctagg ie',\n",
       " 'ok noe u busi realli bore msg u oso dunno wat colour choos one',\n",
       " 'g class earli tomorrow thu tri smoke lt gt',\n",
       " 'superb thought \\\\be grate u dont everyth u want mean u still opportun happier tomorrow u today \\\\',\n",
       " 'hope good week check',\n",
       " 'use hope agent drop sinc book thing year whole boston nyc experi',\n",
       " 'thursday night yeah sure thing work',\n",
       " 'free rington wait collect simpli text password \\\\mix\\\\ verifi get usher britney fml',\n",
       " 'probabl money worri thing come due sever outstand invoic work two three month ago',\n",
       " 'possibl teach',\n",
       " 'wonder phone batteri went dead tell love babe',\n",
       " 'love smell bu tobacco',\n",
       " 'get worri derek taylor alreadi assum worst',\n",
       " 'hey charl sorri late repli',\n",
       " 'lastest stereophon marley dizze racal libertin stroke win nookii game flirt click themob wap bookmark text wap',\n",
       " 'give plu said grinul greet whenev speak',\n",
       " 'white fudg oreo store',\n",
       " 'januari male sale hot gay chat cheaper call nation rate p min cheap p min peak stop text call p min',\n",
       " 'love come took long leav zaher got word ym happi see sad left miss',\n",
       " 'sorri hurt',\n",
       " 'feel nauseou piss eat sweet week caus today plan pig diet week hungri',\n",
       " 'ok lor earli still project meet',\n",
       " 'call da wait call',\n",
       " 'could ask carlo could get anybodi els chip',\n",
       " 'actual send remind today wonder weekend',\n",
       " 'peopl see msg think iam addict msging wrong bcoz don\\\\ know iam addict sweet friend bslvyl',\n",
       " 'hey gave photo regist drive ah tmr wanna meet yck',\n",
       " 'dont talk ever ok word',\n",
       " 'u wana see',\n",
       " 'way school pl send ashley number',\n",
       " 'shall fine avalarr hollalat',\n",
       " 'went attend anoth two round today still reach home',\n",
       " 'actual delet old websit blog magicalsong blogspot com',\n",
       " 'k wait chikku il send aftr lt gt min',\n",
       " 'diet ate mani slice pizza yesterday ugh alway diet',\n",
       " 'k give kvb acc detail',\n",
       " 'oh come ah',\n",
       " 'money r lucki winner claim prize text money million give away ppt x normal text rate box w jy',\n",
       " 'realli sorri b abl friday hope u find altern hope yr term go ok',\n",
       " 'congratul ore mo owo wa enjoy wish mani happi moment fro wherev go',\n",
       " 'samu shoulder yet',\n",
       " 'time think need know near campu',\n",
       " 'dear matthew pleas call landlin complimentari lux tenerif holiday cash await collect ppm sae cs box sk xh',\n",
       " 'dun wear jean lor',\n",
       " 'sinc side fever vomitin',\n",
       " 'k k colleg',\n",
       " 'urgent call landlin complimentari tenerif holiday cash await collect sae cs box hp yf ppm',\n",
       " 'better made friday stuf like pig yesterday feel bleh least writh pain kind bleh',\n",
       " 'sell ton coin sell coin someon thru paypal voila money back life pocket',\n",
       " 'theyr lot place hospit medic place safe',\n",
       " 'get touch folk wait compani txt back name age opt enjoy commun p sm',\n",
       " 'also sorta blown coupl time recent id rather text blue look weed',\n",
       " 'sent score sopha secondari applic school think think appli research cost also contact joke ogunrind school one less expens one',\n",
       " 'cant wait see photo use',\n",
       " 'ur cash balanc current pound maxim ur cash send go p msg cc po box tcr w',\n",
       " 'hey book kb sat alreadi lesson go ah keep sat night free need meet confirm lodg',\n",
       " 'chk ur belovd ms dict',\n",
       " 'time want come',\n",
       " 'awesom lemm know whenev around',\n",
       " 'shb b ok lor thanx',\n",
       " 'beauti truth graviti read care \\\\our heart feel light someon feel heavi someon leav \\\\ good night',\n",
       " 'also rememb get dobbi bowl car',\n",
       " 'filthi stori girl wait',\n",
       " 'sorri c ur msg yar lor poor thing one night tmr u brand new room sleep',\n",
       " 'love decis feel could decid love life would much simpler less magic',\n",
       " 'welp appar retir',\n",
       " 'sort code acc bank natwest repli confirm sent right person',\n",
       " '',\n",
       " 'u sure u take sick time',\n",
       " 'urgent tri contact u today draw show prize guarante call land line claim valid hr',\n",
       " 'watch cartoon listen music amp eve go templ amp church u',\n",
       " 'yo chad gymnast class wanna take site say christian class full',\n",
       " 'much buzi',\n",
       " 'better still catch let ask sell lt gt',\n",
       " 'sure night menu know noon menu',\n",
       " 'u want come back beauti necklac token heart that give wife like see one give dont call wait till come',\n",
       " 'will go aptitud class',\n",
       " 'wont b tri sort hous ok',\n",
       " 'yar lor wan go c hors race today mah eat earlier lor ate chicken rice u',\n",
       " 'haha awesom omw back',\n",
       " 'yup thk e shop close lor',\n",
       " 'account number',\n",
       " 'eh u send wrongli lar',\n",
       " 'hey ad crap nite borin without ya boggi u bore biatch thanx u wait til nxt time il ave ya',\n",
       " 'ok shall talk',\n",
       " 'dont hesit know second time weak like keep notebook eat day anyth chang day sure noth',\n",
       " 'hey pay salari de lt gt',\n",
       " 'anoth month need chocol weed alcohol',\n",
       " 'start search get job day great potenti talent',\n",
       " 'reckon need town eightish walk carpark',\n",
       " 'congrat mobil g videophon r call videochat wid mate play java game dload polyph music nolin rentl',\n",
       " 'look fuckin time fuck think',\n",
       " 'yo guess drop',\n",
       " 'carlo say mu lt gt minut',\n",
       " 'offic call lt gt min',\n",
       " 'geeee miss alreadi know think fuck wait till next year togeth love kiss',\n",
       " 'yun ah ubi one say _ wan call tomorrow call look iren ere got bu ubi cre ubi tech park ph st wkg day n',\n",
       " 'ugh gotta drive back sd la butt sore',\n",
       " 'th juli',\n",
       " 'hi im relax time ever get everi day parti good night get home tomorrow ish',\n",
       " '_ wan come come lor din c stripe skirt',\n",
       " 'xma stori peac xma msg love xma miracl jesu hav bless month ahead amp wish u merri xma',\n",
       " 'number',\n",
       " 'chang e one next escal',\n",
       " 'yetund class run water make ok pl',\n",
       " 'lot happen feel quiet beth aunt charli work lot helen mo',\n",
       " '_ wait bu stop aft ur lect lar dun c _ go get car come back n pick _',\n",
       " 'aight thank comin',\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea42e1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.1-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\fc316le\\appdata\\local\\miniconda3\\lib\\site-packages (from scikit-learn) (2.3.2)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.1-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\fc316le\\appdata\\local\\miniconda3\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.1-cp313-cp313-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/8.7 MB 12.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.8/8.7 MB 4.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.1/8.7 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.9/8.7 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.9/8.7 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.7/8.7 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.7/8.7 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.0/8.7 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.0/8.7 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.2/8.7 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.5/8.7 MB 2.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.0/8.7 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.3/8.7 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.1/8.7 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.1/8.7 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading scipy-1.16.1-cp313-cp313-win_amd64.whl (38.5 MB)\n",
      "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/38.5 MB 5.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.1/38.5 MB 5.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.6/38.5 MB 4.8 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 3.4/38.5 MB 4.2 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 4.2/38.5 MB 4.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 5.0/38.5 MB 4.0 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 5.2/38.5 MB 3.8 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 5.8/38.5 MB 3.6 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 6.6/38.5 MB 3.6 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 7.6/38.5 MB 3.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 8.4/38.5 MB 3.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 8.9/38.5 MB 3.6 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 9.7/38.5 MB 3.6 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 10.5/38.5 MB 3.6 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 11.5/38.5 MB 3.7 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 12.3/38.5 MB 3.8 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 12.8/38.5 MB 3.7 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 13.6/38.5 MB 3.6 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 14.2/38.5 MB 3.6 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 14.9/38.5 MB 3.6 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 16.0/38.5 MB 3.6 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 16.8/38.5 MB 3.6 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 17.3/38.5 MB 3.6 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 17.8/38.5 MB 3.5 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 18.9/38.5 MB 3.6 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 19.4/38.5 MB 3.6 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 20.2/38.5 MB 3.5 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 21.2/38.5 MB 3.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 22.3/38.5 MB 3.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 23.1/38.5 MB 3.6 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 23.9/38.5 MB 3.6 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 24.4/38.5 MB 3.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 24.6/38.5 MB 3.6 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 25.2/38.5 MB 3.5 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 26.0/38.5 MB 3.5 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 26.7/38.5 MB 3.5 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 27.5/38.5 MB 3.5 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 28.6/38.5 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 29.4/38.5 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 29.9/38.5 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 30.7/38.5 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 30.9/38.5 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.7/38.5 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.5/38.5 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.3/38.5 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.3/38.5 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 34.9/38.5 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 35.4/38.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.4/38.5 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.2/38.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.7/38.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.5/38.5 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   ---------------------------------------- 3/3 [scikit-learn]\n",
      "\n",
      "Successfully installed scikit-learn-1.7.1 scipy-1.16.1 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=2500,binary=True)                      #maxfeatures indicate to pick the top2500 most occuring words, rest values are not required\n",
    "                                                                        #binary BOW we make binary as true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf3702b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5573, 2500)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cv.fit_transform(corpus).toarray()                        #max=2500, we are going to have 2500 columsn\n",
    "X.shape                      #to view the size taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d075e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], shape=(5573, 2500))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b5113d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': np.int64(860),\n",
       " 'point': np.int64(1592),\n",
       " 'crazi': np.int64(451),\n",
       " 'avail': np.int64(146),\n",
       " 'bugi': np.int64(279),\n",
       " 'great': np.int64(895),\n",
       " 'world': np.int64(2435),\n",
       " 'la': np.int64(1162),\n",
       " 'cine': np.int64(371),\n",
       " 'got': np.int64(880),\n",
       " 'wat': np.int64(2365),\n",
       " 'ok': np.int64(1479),\n",
       " 'lar': np.int64(1170),\n",
       " 'joke': np.int64(1125),\n",
       " 'wif': np.int64(2403),\n",
       " 'oni': np.int64(1487),\n",
       " 'free': np.int64(769),\n",
       " 'entri': np.int64(619),\n",
       " 'wkli': np.int64(2424),\n",
       " 'comp': np.int64(406),\n",
       " 'win': np.int64(2407),\n",
       " 'fa': np.int64(662),\n",
       " 'cup': np.int64(465),\n",
       " 'final': np.int64(711),\n",
       " 'tkt': np.int64(2210),\n",
       " 'st': np.int64(2054),\n",
       " 'may': np.int64(1308),\n",
       " 'text': np.int64(2169),\n",
       " 'receiv': np.int64(1753),\n",
       " 'question': np.int64(1705),\n",
       " 'std': np.int64(2065),\n",
       " 'txt': np.int64(2267),\n",
       " 'rate': np.int64(1730),\n",
       " 'appli': np.int64(104),\n",
       " 'dun': np.int64(580),\n",
       " 'say': np.int64(1885),\n",
       " 'earli': np.int64(584),\n",
       " 'hor': np.int64(1006),\n",
       " 'alreadi': np.int64(72),\n",
       " 'nah': np.int64(1416),\n",
       " 'think': np.int64(2184),\n",
       " 'goe': np.int64(863),\n",
       " 'usf': np.int64(2310),\n",
       " 'live': np.int64(1224),\n",
       " 'around': np.int64(119),\n",
       " 'though': np.int64(2190),\n",
       " 'freemsg': np.int64(772),\n",
       " 'hey': np.int64(973),\n",
       " 'darl': np.int64(484),\n",
       " 'week': np.int64(2380),\n",
       " 'word': np.int64(2432),\n",
       " 'back': np.int64(159),\n",
       " 'like': np.int64(1213),\n",
       " 'fun': np.int64(795),\n",
       " 'still': np.int64(2067),\n",
       " 'tb': np.int64(2145),\n",
       " 'xxx': np.int64(2463),\n",
       " 'send': np.int64(1913),\n",
       " 'rcv': np.int64(1733),\n",
       " 'even': np.int64(633),\n",
       " 'brother': np.int64(268),\n",
       " 'speak': np.int64(2036),\n",
       " 'treat': np.int64(2245),\n",
       " 'per': np.int64(1541),\n",
       " 'request': np.int64(1795),\n",
       " 'mell': np.int64(1325),\n",
       " 'oru': np.int64(1505),\n",
       " 'minnaminungint': np.int64(1349),\n",
       " 'nurungu': np.int64(1465),\n",
       " 'vettam': np.int64(2324),\n",
       " 'set': np.int64(1925),\n",
       " 'callertun': np.int64(302),\n",
       " 'caller': np.int64(301),\n",
       " 'press': np.int64(1643),\n",
       " 'copi': np.int64(432),\n",
       " 'friend': np.int64(779),\n",
       " 'winner': np.int64(2413),\n",
       " 'valu': np.int64(2316),\n",
       " 'network': np.int64(1433),\n",
       " 'custom': np.int64(469),\n",
       " 'select': np.int64(1908),\n",
       " 'receivea': np.int64(1754),\n",
       " 'prize': np.int64(1656),\n",
       " 'reward': np.int64(1815),\n",
       " 'claim': np.int64(375),\n",
       " 'call': np.int64(298),\n",
       " 'code': np.int64(391),\n",
       " 'valid': np.int64(2315),\n",
       " 'hour': np.int64(1014),\n",
       " 'mobil': np.int64(1365),\n",
       " 'month': np.int64(1379),\n",
       " 'entitl': np.int64(618),\n",
       " 'updat': np.int64(2293),\n",
       " 'latest': np.int64(1175),\n",
       " 'colour': np.int64(398),\n",
       " 'camera': np.int64(307),\n",
       " 'co': np.int64(389),\n",
       " 'gonna': np.int64(869),\n",
       " 'home': np.int64(998),\n",
       " 'soon': np.int64(2020),\n",
       " 'want': np.int64(2359),\n",
       " 'talk': np.int64(2137),\n",
       " 'stuff': np.int64(2088),\n",
       " 'anymor': np.int64(93),\n",
       " 'tonight': np.int64(2227),\n",
       " 'cri': np.int64(455),\n",
       " 'enough': np.int64(616),\n",
       " 'today': np.int64(2217),\n",
       " 'six': np.int64(1978),\n",
       " 'chanc': np.int64(341),\n",
       " 'cash': np.int64(324),\n",
       " 'pound': np.int64(1619),\n",
       " 'cost': np.int64(435),\n",
       " 'day': np.int64(490),\n",
       " 'repli': np.int64(1792),\n",
       " 'hl': np.int64(984),\n",
       " 'info': np.int64(1069),\n",
       " 'urgent': np.int64(2301),\n",
       " 'membership': np.int64(1327),\n",
       " 'www': np.int64(2454),\n",
       " 'net': np.int64(1431),\n",
       " 'pobox': np.int64(1588),\n",
       " 'ldnw': np.int64(1183),\n",
       " 'rw': np.int64(1859),\n",
       " 'search': np.int64(1898),\n",
       " 'right': np.int64(1822),\n",
       " 'thank': np.int64(2176),\n",
       " 'promis': np.int64(1669),\n",
       " 'wont': np.int64(2431),\n",
       " 'take': np.int64(2133),\n",
       " 'help': np.int64(966),\n",
       " 'wonder': np.int64(2430),\n",
       " 'bless': np.int64(226),\n",
       " 'time': np.int64(2206),\n",
       " 'date': np.int64(488),\n",
       " 'sunday': np.int64(2105),\n",
       " 'use': np.int64(2308),\n",
       " 'credit': np.int64(454),\n",
       " 'click': np.int64(380),\n",
       " 'wap': np.int64(2360),\n",
       " 'link': np.int64(1218),\n",
       " 'next': np.int64(1439),\n",
       " 'messag': np.int64(1333),\n",
       " 'http': np.int64(1026),\n",
       " 'com': np.int64(399),\n",
       " 'oh': np.int64(1477),\n",
       " 'watch': np.int64(2366),\n",
       " 'eh': np.int64(599),\n",
       " 'rememb': np.int64(1781),\n",
       " 'spell': np.int64(2040),\n",
       " 'name': np.int64(1418),\n",
       " 'ye': np.int64(2473),\n",
       " 'naughti': np.int64(1424),\n",
       " 'make': np.int64(1283),\n",
       " 'wet': np.int64(2392),\n",
       " 'fine': np.int64(714),\n",
       " 'way': np.int64(2369),\n",
       " 'feel': np.int64(693),\n",
       " 'england': np.int64(613),\n",
       " 'dont': np.int64(560),\n",
       " 'miss': np.int64(1352),\n",
       " 'goal': np.int64(861),\n",
       " 'team': np.int64(2151),\n",
       " 'news': np.int64(1438),\n",
       " 'ur': np.int64(2298),\n",
       " 'nation': np.int64(1422),\n",
       " 'eg': np.int64(597),\n",
       " 'tri': np.int64(2247),\n",
       " 'wale': np.int64(2351),\n",
       " 'scotland': np.int64(1893),\n",
       " 'wq': np.int64(2443),\n",
       " 'serious': np.int64(1922),\n",
       " 'ha': np.int64(917),\n",
       " 'pay': np.int64(1533),\n",
       " 'first': np.int64(718),\n",
       " 'da': np.int64(475),\n",
       " 'stock': np.int64(2068),\n",
       " 'comin': np.int64(403),\n",
       " 'aft': np.int64(43),\n",
       " 'finish': np.int64(716),\n",
       " 'lunch': np.int64(1265),\n",
       " 'str': np.int64(2078),\n",
       " 'lor': np.int64(1243),\n",
       " 'ard': np.int64(111),\n",
       " 'smth': np.int64(2001),\n",
       " 'alright': np.int64(73),\n",
       " 'meet': np.int64(1321),\n",
       " 'sooner': np.int64(2021),\n",
       " 'forc': np.int64(749),\n",
       " 'eat': np.int64(590),\n",
       " 'slice': np.int64(1990),\n",
       " 'realli': np.int64(1746),\n",
       " 'hungri': np.int64(1032),\n",
       " 'tho': np.int64(2189),\n",
       " 'suck': np.int64(2097),\n",
       " 'mark': np.int64(1295),\n",
       " 'get': np.int64(840),\n",
       " 'worri': np.int64(2436),\n",
       " 'know': np.int64(1159),\n",
       " 'sick': np.int64(1960),\n",
       " 'turn': np.int64(2262),\n",
       " 'pizza': np.int64(1570),\n",
       " 'lol': np.int64(1235),\n",
       " 'alway': np.int64(76),\n",
       " 'convinc': np.int64(429),\n",
       " 'catch': np.int64(326),\n",
       " 'bu': np.int64(274),\n",
       " 'fri': np.int64(777),\n",
       " 'egg': np.int64(598),\n",
       " 'tea': np.int64(2148),\n",
       " 'mom': np.int64(1372),\n",
       " 'left': np.int64(1191),\n",
       " 'dinner': np.int64(537),\n",
       " 'love': np.int64(1253),\n",
       " 'amp': np.int64(83),\n",
       " 'pack': np.int64(1517),\n",
       " 'car': np.int64(315),\n",
       " 'let': np.int64(1200),\n",
       " 'room': np.int64(1840),\n",
       " 'work': np.int64(2433),\n",
       " 'wait': np.int64(2348),\n",
       " 'clear': np.int64(379),\n",
       " 'sure': np.int64(2117),\n",
       " 'sarcast': np.int64(1876),\n",
       " 'us': np.int64(2306),\n",
       " 'yeah': np.int64(2474),\n",
       " 'child': np.int64(359),\n",
       " 'caught': np.int64(327),\n",
       " 'till': np.int64(2205),\n",
       " 'cheer': np.int64(355),\n",
       " 'tell': np.int64(2158),\n",
       " 'anyth': np.int64(95),\n",
       " 'fear': np.int64(689),\n",
       " 'quick': np.int64(1706),\n",
       " 'subscript': np.int64(2095),\n",
       " 'rington': np.int64(1825),\n",
       " 'uk': np.int64(2276),\n",
       " 'charg': np.int64(345),\n",
       " 'pleas': np.int64(1580),\n",
       " 'confirm': np.int64(417),\n",
       " 'yup': np.int64(2497),\n",
       " 'look': np.int64(1240),\n",
       " 'msg': np.int64(1399),\n",
       " 'xuhui': np.int64(2461),\n",
       " 'learn': np.int64(1186),\n",
       " 'nd': np.int64(1425),\n",
       " 'lesson': np.int64(1199),\n",
       " 'oop': np.int64(1491),\n",
       " 'roommat': np.int64(1841),\n",
       " 'done': np.int64(559),\n",
       " 'see': np.int64(1905),\n",
       " 'letter': np.int64(1201),\n",
       " 'decid': np.int64(499),\n",
       " 'hello': np.int64(964),\n",
       " 'saturday': np.int64(1880),\n",
       " 'tomo': np.int64(2224),\n",
       " 'invit': np.int64(1085),\n",
       " 'pl': np.int64(1571),\n",
       " 'ahead': np.int64(50),\n",
       " 'weekend': np.int64(2381),\n",
       " 'abiola': np.int64(4),\n",
       " 'forget': np.int64(753),\n",
       " 'need': np.int64(1429),\n",
       " 'crave': np.int64(450),\n",
       " 'sweet': np.int64(2121),\n",
       " 'yummi': np.int64(2493),\n",
       " 'burn': np.int64(283),\n",
       " 'sm': np.int64(1995),\n",
       " 'nokia': np.int64(1450),\n",
       " 'camcord': np.int64(305),\n",
       " 'deliveri': np.int64(511),\n",
       " 'tomorrow': np.int64(2225),\n",
       " 'hope': np.int64(1005),\n",
       " 'man': np.int64(1287),\n",
       " 'well': np.int64(2387),\n",
       " 'lt': np.int64(1260),\n",
       " 'gt': np.int64(905),\n",
       " 'inch': np.int64(1062),\n",
       " 'nigeria': np.int64(1443),\n",
       " 'fair': np.int64(667),\n",
       " 'tyler': np.int64(2271),\n",
       " 'could': np.int64(437),\n",
       " 'mayb': np.int64(1309),\n",
       " 'ask': np.int64(127),\n",
       " 'bit': np.int64(216),\n",
       " 'hospit': np.int64(1010),\n",
       " 'kept': np.int64(1143),\n",
       " 'weak': np.int64(2372),\n",
       " 'saw': np.int64(1884),\n",
       " 'class': np.int64(377),\n",
       " 'gram': np.int64(889),\n",
       " 'usual': np.int64(2311),\n",
       " 'run': np.int64(1857),\n",
       " 'half': np.int64(925),\n",
       " 'almost': np.int64(69),\n",
       " 'whole': np.int64(2401),\n",
       " 'second': np.int64(1902),\n",
       " 'fyi': np.int64(804),\n",
       " 'ride': np.int64(1821),\n",
       " 'morn': np.int64(1384),\n",
       " 'crash': np.int64(449),\n",
       " 'place': np.int64(1572),\n",
       " 'wow': np.int64(2441),\n",
       " 'never': np.int64(1435),\n",
       " 'realiz': np.int64(1745),\n",
       " 'embarass': np.int64(606),\n",
       " 'thought': np.int64(2191),\n",
       " 'sinc': np.int64(1969),\n",
       " 'best': np.int64(199),\n",
       " 'seem': np.int64(1906),\n",
       " 'happi': np.int64(937),\n",
       " 'sorri': np.int64(2024),\n",
       " 'give': np.int64(855),\n",
       " 'offer': np.int64(1473),\n",
       " 'ac': np.int64(12),\n",
       " 'new': np.int64(1436),\n",
       " 'red': np.int64(1762),\n",
       " 'play': np.int64(1577),\n",
       " 'ice': np.int64(1043),\n",
       " 'hockey': np.int64(991),\n",
       " 'correct': np.int64(434),\n",
       " 'end': np.int64(608),\n",
       " 'yesterday': np.int64(2480),\n",
       " 'find': np.int64(713),\n",
       " 'url': np.int64(2303),\n",
       " 'congrat': np.int64(419),\n",
       " 'year': np.int64(2475),\n",
       " 'special': np.int64(2037),\n",
       " 'cinema': np.int64(372),\n",
       " 'pass': np.int64(1529),\n",
       " 'suprman': np.int64(2115),\n",
       " 'matrix': np.int64(1303),\n",
       " 'starwar': np.int64(2061),\n",
       " 'etc': np.int64(630),\n",
       " 'bx': np.int64(289),\n",
       " 'ip': np.int64(1088),\n",
       " 'pm': np.int64(1586),\n",
       " 'later': np.int64(1174),\n",
       " 'reach': np.int64(1736),\n",
       " 'seri': np.int64(1920),\n",
       " 'pick': np.int64(1557),\n",
       " 'burger': np.int64(282),\n",
       " 'move': np.int64(1392),\n",
       " 'pain': np.int64(1521),\n",
       " 'kill': np.int64(1150),\n",
       " 'good': np.int64(870),\n",
       " 'girl': np.int64(851),\n",
       " 'situat': np.int64(1977),\n",
       " 'part': np.int64(1526),\n",
       " 'check': np.int64(354),\n",
       " 'iq': np.int64(1091),\n",
       " 'took': np.int64(2229),\n",
       " 'forev': np.int64(751),\n",
       " 'come': np.int64(401),\n",
       " 'doubl': np.int64(563),\n",
       " 'hair': np.int64(923),\n",
       " 'dresser': np.int64(568),\n",
       " 'said': np.int64(1868),\n",
       " 'wun': np.int64(2453),\n",
       " 'cut': np.int64(470),\n",
       " 'short': np.int64(1948),\n",
       " 'nice': np.int64(1441),\n",
       " 'advis': np.int64(38),\n",
       " 'follow': np.int64(741),\n",
       " 'recent': np.int64(1755),\n",
       " 'review': np.int64(1813),\n",
       " 'mob': np.int64(1363),\n",
       " 'award': np.int64(153),\n",
       " 'bonu': np.int64(240),\n",
       " 'song': np.int64(2017),\n",
       " 'dedic': np.int64(502),\n",
       " 'valuabl': np.int64(2317),\n",
       " 'frnd': np.int64(783),\n",
       " 'rpli': np.int64(1846),\n",
       " 'complimentari': np.int64(410),\n",
       " 'trip': np.int64(2248),\n",
       " 'di': np.int64(522),\n",
       " 'ls': np.int64(1259),\n",
       " 'hear': np.int64(953),\n",
       " 'plane': np.int64(1575),\n",
       " 'wah': np.int64(2347),\n",
       " 'lucki': np.int64(1263),\n",
       " 'save': np.int64(1883),\n",
       " 'money': np.int64(1376),\n",
       " 'hee': np.int64(958),\n",
       " 'hi': np.int64(975),\n",
       " 'babe': np.int64(157),\n",
       " 'im': np.int64(1053),\n",
       " 'wanna': np.int64(2358),\n",
       " 'someth': np.int64(2013),\n",
       " 'xx': np.int64(2462),\n",
       " 'perform': np.int64(1544),\n",
       " 'machan': np.int64(1271),\n",
       " 'that': np.int64(2179),\n",
       " 'cool': np.int64(431),\n",
       " 'gentleman': np.int64(835),\n",
       " 'digniti': np.int64(534),\n",
       " 'respect': np.int64(1799),\n",
       " 'peopl': np.int64(1540),\n",
       " 'much': np.int64(1407),\n",
       " 'shi': np.int64(1939),\n",
       " 'pa': np.int64(1516),\n",
       " 'oper': np.int64(1493),\n",
       " 'job': np.int64(1121),\n",
       " 'ta': np.int64(2130),\n",
       " 'earn': np.int64(586),\n",
       " 'ah': np.int64(48),\n",
       " 'stop': np.int64(2073),\n",
       " 'urgnt': np.int64(2302),\n",
       " 'real': np.int64(1741),\n",
       " 'yo': np.int64(2486),\n",
       " 'ticket': np.int64(2202),\n",
       " 'one': np.int64(1486),\n",
       " 'start': np.int64(2060),\n",
       " 'came': np.int64(306),\n",
       " 'bed': np.int64(185),\n",
       " 'coin': np.int64(393),\n",
       " 'gotta': np.int64(882),\n",
       " 'nitro': np.int64(1447),\n",
       " 'kano': np.int64(1138),\n",
       " 'il': np.int64(1051),\n",
       " 'download': np.int64(564),\n",
       " 'wen': np.int64(2389),\n",
       " 'stand': np.int64(2057),\n",
       " 'close': np.int64(383),\n",
       " 'anoth': np.int64(88),\n",
       " 'night': np.int64(1444),\n",
       " 'spent': np.int64(2042),\n",
       " 'late': np.int64(1173),\n",
       " 'afternoon': np.int64(44),\n",
       " 'mean': np.int64(1314),\n",
       " 'moro': np.int64(1385),\n",
       " 'includ': np.int64(1064),\n",
       " 'sheet': np.int64(1937),\n",
       " 'smile': np.int64(1999),\n",
       " 'pleasur': np.int64(1581),\n",
       " 'troubl': np.int64(2249),\n",
       " 'pour': np.int64(1620),\n",
       " 'rain': np.int64(1718),\n",
       " 'sum': np.int64(2102),\n",
       " 'hurt': np.int64(1035),\n",
       " 'becoz': np.int64(184),\n",
       " 'someon': np.int64(2012),\n",
       " 'servic': np.int64(1924),\n",
       " 'repres': np.int64(1794),\n",
       " 'guarante': np.int64(907),\n",
       " 'havent': np.int64(945),\n",
       " 'plan': np.int64(1574),\n",
       " 'buy': np.int64(286),\n",
       " 'lido': np.int64(1205),\n",
       " 'show': np.int64(1955),\n",
       " 'collect': np.int64(396),\n",
       " 'simpli': np.int64(1968),\n",
       " 'password': np.int64(1531),\n",
       " 'mix': np.int64(1356),\n",
       " 'verifi': np.int64(2322),\n",
       " 'fml': np.int64(738),\n",
       " 'movi': np.int64(1393),\n",
       " 'abt': np.int64(8),\n",
       " 'load': np.int64(1227),\n",
       " 'loan': np.int64(1228),\n",
       " 'wk': np.int64(2421),\n",
       " 'hol': np.int64(992),\n",
       " 'forgot': np.int64(756),\n",
       " 'appoint': np.int64(105),\n",
       " 'four': np.int64(764),\n",
       " 'shower': np.int64(1956),\n",
       " 'caus': np.int64(328),\n",
       " 'prob': np.int64(1658),\n",
       " 'noth': np.int64(1458),\n",
       " 'els': np.int64(602),\n",
       " 'okay': np.int64(1480),\n",
       " 'price': np.int64(1648),\n",
       " 'long': np.int64(1238),\n",
       " 'legal': np.int64(1193),\n",
       " 'ave': np.int64(148),\n",
       " 'gone': np.int64(868),\n",
       " 'drive': np.int64(571),\n",
       " 'test': np.int64(2168),\n",
       " 'yet': np.int64(2481),\n",
       " 'guess': np.int64(910),\n",
       " 'gave': np.int64(820),\n",
       " 'boston': np.int64(248),\n",
       " 'men': np.int64(1328),\n",
       " 'chang': np.int64(342),\n",
       " 'locat': np.int64(1230),\n",
       " 'nyc': np.int64(1469),\n",
       " 'cuz': np.int64(473),\n",
       " 'page': np.int64(1519),\n",
       " 'umma': np.int64(2277),\n",
       " 'life': np.int64(1207),\n",
       " 'vava': np.int64(2320),\n",
       " 'lot': np.int64(1247),\n",
       " 'dear': np.int64(494),\n",
       " 'wish': np.int64(2416),\n",
       " 'birthday': np.int64(214),\n",
       " 'truli': np.int64(2251),\n",
       " 'aight': np.int64(52),\n",
       " 'hit': np.int64(982),\n",
       " 'would': np.int64(2440),\n",
       " 'address': np.int64(31),\n",
       " 'consid': np.int64(422),\n",
       " 'comput': np.int64(411),\n",
       " 'old': np.int64(1483),\n",
       " 'better': np.int64(201),\n",
       " 'lie': np.int64(1206),\n",
       " 'busi': np.int64(284),\n",
       " 'research': np.int64(1797),\n",
       " 'thing': np.int64(2183),\n",
       " 'scare': np.int64(1886),\n",
       " 'mah': np.int64(1278),\n",
       " 'loud': np.int64(1249),\n",
       " 'gent': np.int64(833),\n",
       " 'contact': np.int64(424),\n",
       " 'last': np.int64(1172),\n",
       " 'draw': np.int64(565),\n",
       " 'hr': np.int64(1023),\n",
       " 'ppm': np.int64(1627),\n",
       " 'wa': np.int64(2346),\n",
       " 'sentenc': np.int64(1917),\n",
       " 'formal': np.int64(759),\n",
       " 'anyway': np.int64(98),\n",
       " 'juz': np.int64(1135),\n",
       " 'tt': np.int64(2257),\n",
       " 'eatin': np.int64(592),\n",
       " 'puttin': np.int64(1696),\n",
       " 'weight': np.int64(2384),\n",
       " 'haha': np.int64(920),\n",
       " 'anythin': np.int64(96),\n",
       " 'happen': np.int64(935),\n",
       " 'enter': np.int64(617),\n",
       " 'cabin': np.int64(291),\n",
       " 'boss': np.int64(247),\n",
       " 'felt': np.int64(697),\n",
       " 'askd': np.int64(128),\n",
       " 'apart': np.int64(100),\n",
       " 'went': np.int64(2390),\n",
       " 'holiday': np.int64(996),\n",
       " 'flight': np.int64(732),\n",
       " 'inc': np.int64(1061),\n",
       " 'min': np.int64(1344),\n",
       " 'goodo': np.int64(876),\n",
       " 'must': np.int64(1413),\n",
       " 'friday': np.int64(778),\n",
       " 'potato': np.int64(1615),\n",
       " 'hmm': np.int64(987),\n",
       " 'uncl': np.int64(2281),\n",
       " 'inform': np.int64(1070),\n",
       " 'school': np.int64(1890),\n",
       " 'directli': np.int64(540),\n",
       " 'food': np.int64(743),\n",
       " 'privat': np.int64(1655),\n",
       " 'account': np.int64(20),\n",
       " 'statement': np.int64(2062),\n",
       " 'unredeem': np.int64(2289),\n",
       " 'identifi': np.int64(1046),\n",
       " 'expir': np.int64(657),\n",
       " 'landlin': np.int64(1168),\n",
       " 'box': np.int64(255),\n",
       " 'voda': np.int64(2337),\n",
       " 'number': np.int64(1464),\n",
       " 'match': np.int64(1300),\n",
       " 'quot': np.int64(1711),\n",
       " 'standard': np.int64(2058),\n",
       " 'app': np.int64(102),\n",
       " 'mu': np.int64(1406),\n",
       " 'predict': np.int64(1633),\n",
       " 'yetund': np.int64(2482),\n",
       " 'sent': np.int64(1916),\n",
       " 'bother': np.int64(249),\n",
       " 'apologis': np.int64(101),\n",
       " 'del': np.int64(506),\n",
       " 'bak': np.int64(163),\n",
       " 'answer': np.int64(90),\n",
       " 'sunshin': np.int64(2107),\n",
       " 'quiz': np.int64(1710),\n",
       " 'top': np.int64(2230),\n",
       " 'soni': np.int64(2018),\n",
       " 'dvd': np.int64(582),\n",
       " 'player': np.int64(1578),\n",
       " 'countri': np.int64(439),\n",
       " 'ansr': np.int64(89),\n",
       " 'sp': np.int64(2032),\n",
       " 'tyron': np.int64(2273),\n",
       " 'laid': np.int64(1166),\n",
       " 'dog': np.int64(554),\n",
       " 'direct': np.int64(539),\n",
       " 'join': np.int64(1124),\n",
       " 'largest': np.int64(1171),\n",
       " 'bt': np.int64(272),\n",
       " 'txting': np.int64(2270),\n",
       " 'nt': np.int64(1460),\n",
       " 'ec': np.int64(593),\n",
       " 'haf': np.int64(919),\n",
       " 'yiju': np.int64(2484),\n",
       " 'befor': np.int64(188),\n",
       " 'activ': np.int64(25),\n",
       " 'chat': np.int64(349),\n",
       " 'hardcor': np.int64(940),\n",
       " 'age': np.int64(46),\n",
       " 'yr': np.int64(2492),\n",
       " 'lazi': np.int64(1180),\n",
       " 'type': np.int64(2272),\n",
       " 'lect': np.int64(1189),\n",
       " 'pouch': np.int64(1618),\n",
       " 'sir': np.int64(1973),\n",
       " 'mail': np.int64(1280),\n",
       " 'swt': np.int64(2126),\n",
       " 'tire': np.int64(2207),\n",
       " 'littl': np.int64(1223),\n",
       " 'lovabl': np.int64(1252),\n",
       " 'person': np.int64(1546),\n",
       " 'coz': np.int64(444),\n",
       " 'occupi': np.int64(1472),\n",
       " 'biggest': np.int64(208),\n",
       " 'heart': np.int64(955),\n",
       " 'gud': np.int64(908),\n",
       " 'ni': np.int64(1440),\n",
       " 'open': np.int64(1492),\n",
       " 'ya': np.int64(2468),\n",
       " 'dot': np.int64(562),\n",
       " 'what': np.int64(2393),\n",
       " 'staff': np.int64(2055),\n",
       " 'randi': np.int64(1725),\n",
       " 'sexi': np.int64(1929),\n",
       " 'femal': np.int64(698),\n",
       " 'local': np.int64(1229),\n",
       " 'luv': np.int64(1266),\n",
       " 'netcollex': np.int64(1432),\n",
       " 'ltd': np.int64(1261),\n",
       " 'begin': np.int64(190),\n",
       " 'qatar': np.int64(1699),\n",
       " 'pray': np.int64(1631),\n",
       " 'hard': np.int64(939),\n",
       " 'delet': np.int64(508),\n",
       " 'birla': np.int64(212),\n",
       " 'soft': np.int64(2007),\n",
       " 'wine': np.int64(2412),\n",
       " 'flow': np.int64(736),\n",
       " 'thk': np.int64(2186),\n",
       " 'plaza': np.int64(1579),\n",
       " 'floor': np.int64(735),\n",
       " 'window': np.int64(2411),\n",
       " 'shirt': np.int64(1942),\n",
       " 'sometim': np.int64(2015),\n",
       " 'dream': np.int64(566),\n",
       " 'without': np.int64(2419),\n",
       " 'joy': np.int64(1128),\n",
       " 'tv': np.int64(2263),\n",
       " 'becom': np.int64(183),\n",
       " 'leav': np.int64(1188),\n",
       " 'hous': np.int64(1015),\n",
       " 'interview': np.int64(1083),\n",
       " 'boy': np.int64(256),\n",
       " 'arrang': np.int64(120),\n",
       " 'keep': np.int64(1142),\n",
       " 'safe': np.int64(1867),\n",
       " 'everyon': np.int64(638),\n",
       " 'parent': np.int64(1523),\n",
       " 'hand': np.int64(930),\n",
       " 'excit': np.int64(649),\n",
       " 'spend': np.int64(2041),\n",
       " 'order': np.int64(1501),\n",
       " 'content': np.int64(425),\n",
       " 'goto': np.int64(881),\n",
       " 'internet': np.int64(1082),\n",
       " 'menu': np.int64(1330),\n",
       " 'modul': np.int64(1370),\n",
       " 'avoid': np.int64(150),\n",
       " 'wit': np.int64(2417),\n",
       " 'escap': np.int64(625),\n",
       " 'fanci': np.int64(671),\n",
       " 'complet': np.int64(409),\n",
       " 'form': np.int64(758),\n",
       " 'also': np.int64(75),\n",
       " 'utter': np.int64(2312),\n",
       " 'wast': np.int64(2364),\n",
       " 'bank': np.int64(166),\n",
       " 'hmmm': np.int64(988),\n",
       " 'hop': np.int64(1004),\n",
       " 'muz': np.int64(1414),\n",
       " 'discuss': np.int64(544),\n",
       " 'liao': np.int64(1202),\n",
       " 'bloodi': np.int64(231),\n",
       " 'hell': np.int64(962),\n",
       " 'cant': np.int64(313),\n",
       " 'believ': np.int64(194),\n",
       " 'mr': np.int64(1395),\n",
       " 'ill': np.int64(1052),\n",
       " 'spanish': np.int64(2034),\n",
       " 'bath': np.int64(172),\n",
       " 'carlo': np.int64(320),\n",
       " 'mall': np.int64(1286),\n",
       " 'stay': np.int64(2064),\n",
       " 'til': np.int64(2204),\n",
       " 'smoke': np.int64(2000),\n",
       " 'worth': np.int64(2438),\n",
       " 'doesnt': np.int64(553),\n",
       " 'log': np.int64(1232),\n",
       " 'spoke': np.int64(2046),\n",
       " 'maneesha': np.int64(1290),\n",
       " 'satisfi': np.int64(1879),\n",
       " 'experi': np.int64(656),\n",
       " 'toll': np.int64(2221),\n",
       " 'lift': np.int64(1210),\n",
       " 'especi': np.int64(627),\n",
       " 'studi': np.int64(2087),\n",
       " 'gr': np.int64(886),\n",
       " 'trust': np.int64(2252),\n",
       " 'guy': np.int64(913),\n",
       " 'bye': np.int64(290),\n",
       " 'handsom': np.int64(933),\n",
       " 'toward': np.int64(2237),\n",
       " 'mummi': np.int64(1409),\n",
       " 'boytoy': np.int64(257),\n",
       " 'awesom': np.int64(155),\n",
       " 'minut': np.int64(1350),\n",
       " 'freephon': np.int64(773),\n",
       " 'xma': np.int64(2460),\n",
       " 'radio': np.int64(1715),\n",
       " 'ju': np.int64(1131),\n",
       " 'si': np.int64(1959),\n",
       " 'uniqu': np.int64(2285),\n",
       " 'th': np.int64(2174),\n",
       " 'august': np.int64(142),\n",
       " 'touch': np.int64(2234),\n",
       " 'deal': np.int64(493),\n",
       " 'cours': np.int64(442),\n",
       " 'howev': np.int64(1019),\n",
       " 'suggest': np.int64(2100),\n",
       " 'abl': np.int64(6),\n",
       " 'everi': np.int64(636),\n",
       " 'settl': np.int64(1926),\n",
       " 'mrng': np.int64(1396),\n",
       " 'hav': np.int64(944),\n",
       " 'stori': np.int64(2076),\n",
       " 'hamster': np.int64(929),\n",
       " 'dead': np.int64(492),\n",
       " 'tmr': np.int64(2213),\n",
       " 'orchard': np.int64(1500),\n",
       " 'mrt': np.int64(1397),\n",
       " 'kate': np.int64(1140),\n",
       " 'found': np.int64(763),\n",
       " 'buck': np.int64(275),\n",
       " 'darlin': np.int64(485),\n",
       " 'ive': np.int64(1101),\n",
       " 'colleg': np.int64(397),\n",
       " 'refil': np.int64(1767),\n",
       " 'success': np.int64(2096),\n",
       " 'decim': np.int64(500),\n",
       " 'prepaid': np.int64(1638),\n",
       " 'balanc': np.int64(164),\n",
       " 'rs': np.int64(1848),\n",
       " 'transact': np.int64(2241),\n",
       " 'id': np.int64(1044),\n",
       " 'goodmorn': np.int64(872),\n",
       " 'sleep': np.int64(1988),\n",
       " 'ga': np.int64(805),\n",
       " 'dat': np.int64(487),\n",
       " 'oso': np.int64(1506),\n",
       " 'cannot': np.int64(312),\n",
       " 'oredi': np.int64(1502),\n",
       " 'straight': np.int64(2079),\n",
       " 'connect': np.int64(421),\n",
       " 'refund': np.int64(1768),\n",
       " 'bill': np.int64(209),\n",
       " 'shoot': np.int64(1946),\n",
       " 'big': np.int64(206),\n",
       " 'readi': np.int64(1740),\n",
       " 'break': np.int64(260),\n",
       " 'semest': np.int64(1911),\n",
       " 'noe': np.int64(1449),\n",
       " 'leh': np.int64(1194),\n",
       " 'sound': np.int64(2028),\n",
       " 'head': np.int64(950),\n",
       " 'slept': np.int64(1989),\n",
       " 'past': np.int64(1532),\n",
       " 'easi': np.int64(588),\n",
       " 'sen': np.int64(1912),\n",
       " 'exam': np.int64(646),\n",
       " 'march': np.int64(1293),\n",
       " 'atm': np.int64(135),\n",
       " 'regist': np.int64(1772),\n",
       " 'instal': np.int64(1074),\n",
       " 'import': np.int64(1057),\n",
       " 'file': np.int64(707),\n",
       " 'system': np.int64(2129),\n",
       " 'repair': np.int64(1789),\n",
       " 'shop': np.int64(1947),\n",
       " 'romant': np.int64(1838),\n",
       " 'nite': np.int64(1446),\n",
       " 'tc': np.int64(2146),\n",
       " 'biz': np.int64(219),\n",
       " 'optout': np.int64(1498),\n",
       " 'gbp': np.int64(824),\n",
       " 'mtmsg': np.int64(1404),\n",
       " 'appreci': np.int64(106),\n",
       " 'partner': np.int64(1528),\n",
       " 'career': np.int64(319),\n",
       " 'horo': np.int64(1008),\n",
       " 'star': np.int64(2059),\n",
       " 'sign': np.int64(1964),\n",
       " 'compani': np.int64(407),\n",
       " 'po': np.int64(1587),\n",
       " 'teacher': np.int64(2150),\n",
       " 'bcoz': np.int64(177),\n",
       " 'teach': np.int64(2149),\n",
       " 'walk': np.int64(2352),\n",
       " 'cross': np.int64(457),\n",
       " 'road': np.int64(1831),\n",
       " 'side': np.int64(1961),\n",
       " 'street': np.int64(2081),\n",
       " 'batteri': np.int64(173),\n",
       " 'die': np.int64(527),\n",
       " 'flirt': np.int64(734),\n",
       " 'sam': np.int64(1874),\n",
       " 'recd': np.int64(1751),\n",
       " 'penc': np.int64(1538),\n",
       " 'print': np.int64(1652),\n",
       " 'closer': np.int64(384),\n",
       " 'wil': np.int64(2405),\n",
       " 'theori': np.int64(2182),\n",
       " 'argument': np.int64(115),\n",
       " 'lose': np.int64(1244),\n",
       " 'argu': np.int64(114),\n",
       " 'kick': np.int64(1147),\n",
       " 'secret': np.int64(1903),\n",
       " 'admir': np.int64(32),\n",
       " 'reveal': np.int64(1811),\n",
       " 'tomarrow': np.int64(2223),\n",
       " 'laptop': np.int64(1169),\n",
       " 'case': np.int64(323),\n",
       " 'tel': np.int64(2156),\n",
       " 'avent': np.int64(149),\n",
       " 'meant': np.int64(1315),\n",
       " 'told': np.int64(2220),\n",
       " 'face': np.int64(663),\n",
       " 'fr': np.int64(765),\n",
       " 'thanx': np.int64(2178),\n",
       " 'everyth': np.int64(639),\n",
       " 'websit': np.int64(2376),\n",
       " 'slipper': np.int64(1992),\n",
       " 'kalli': np.int64(1137),\n",
       " 'bat': np.int64(171),\n",
       " 'inning': np.int64(1071),\n",
       " 'didnt': np.int64(526),\n",
       " 'goodnight': np.int64(873),\n",
       " 'fix': np.int64(722),\n",
       " 'wake': np.int64(2350),\n",
       " 'dearli': np.int64(496),\n",
       " 'congratul': np.int64(420),\n",
       " 'cd': np.int64(331),\n",
       " 'voucher': np.int64(2344),\n",
       " 'gift': np.int64(848),\n",
       " 'music': np.int64(1412),\n",
       " 'tnc': np.int64(2214),\n",
       " 'ldew': np.int64(1181),\n",
       " 'ppmx': np.int64(1628),\n",
       " 'ranjith': np.int64(1729),\n",
       " 'cal': np.int64(294),\n",
       " 'hold': np.int64(993),\n",
       " 'bcum': np.int64(178),\n",
       " 'angri': np.int64(86),\n",
       " 'wid': np.int64(2402),\n",
       " 'dnt': np.int64(550),\n",
       " 'childish': np.int64(360),\n",
       " 'true': np.int64(2250),\n",
       " 'deep': np.int64(503),\n",
       " 'affect': np.int64(41),\n",
       " 'care': np.int64(318),\n",
       " 'kettoda': np.int64(1145),\n",
       " 'manda': np.int64(1289),\n",
       " 'ship': np.int64(1941),\n",
       " 'lemm': np.int64(1196),\n",
       " 'expect': np.int64(654),\n",
       " 'headin': np.int64(952),\n",
       " 'mmm': np.int64(1358),\n",
       " 'lover': np.int64(1254),\n",
       " 'video': np.int64(2326),\n",
       " 'handset': np.int64(932),\n",
       " 'anytim': np.int64(97),\n",
       " 'unlimit': np.int64(2288),\n",
       " 'park': np.int64(1525),\n",
       " 'mini': np.int64(1347),\n",
       " 'disturb': np.int64(548),\n",
       " 'ring': np.int64(1824),\n",
       " 'horni': np.int64(1007),\n",
       " 'nake': np.int64(1417),\n",
       " 'hot': np.int64(1012),\n",
       " 'unsubscrib': np.int64(2292),\n",
       " 'dint': np.int64(538),\n",
       " 'wana': np.int64(2357),\n",
       " 'club': np.int64(386),\n",
       " 'choos': np.int64(367),\n",
       " 'wt': np.int64(2449),\n",
       " 'flash': np.int64(729),\n",
       " 'jealou': np.int64(1115),\n",
       " 'singl': np.int64(1971),\n",
       " 'chart': np.int64(347),\n",
       " 'qualiti': np.int64(1702),\n",
       " 'sort': np.int64(2026),\n",
       " 'sunni': np.int64(2106),\n",
       " 'ray': np.int64(1732),\n",
       " 'blue': np.int64(234),\n",
       " 'bay': np.int64(174),\n",
       " 'hmv': np.int64(989),\n",
       " 'genuin': np.int64(837),\n",
       " 'percent': np.int64(1542),\n",
       " 'might': np.int64(1340),\n",
       " 'bf': np.int64(204),\n",
       " 'rob': np.int64(1833),\n",
       " 'gf': np.int64(845),\n",
       " 'celebr': np.int64(333),\n",
       " 'full': np.int64(793),\n",
       " 'swing': np.int64(2124),\n",
       " 'far': np.int64(674),\n",
       " 'oki': np.int64(1482),\n",
       " 'anybodi': np.int64(92),\n",
       " 'throw': np.int64(2195),\n",
       " 'babi': np.int64(158),\n",
       " 'fone': np.int64(742),\n",
       " 'ge': np.int64(826),\n",
       " 'shall': np.int64(1933),\n",
       " 'tonit': np.int64(2228),\n",
       " 'sens': np.int64(1915),\n",
       " 'gautham': np.int64(819),\n",
       " 'stupid': np.int64(2089),\n",
       " 'cam': np.int64(304),\n",
       " 'buzi': np.int64(287),\n",
       " 'accident': np.int64(18),\n",
       " 'phone': np.int64(1554),\n",
       " 'upgrad': np.int64(2294),\n",
       " 'sim': np.int64(1966),\n",
       " 'card': np.int64(316),\n",
       " 'loyalti': np.int64(1257),\n",
       " 'unless': np.int64(2287),\n",
       " 'teas': np.int64(2153),\n",
       " 'plz': np.int64(1585),\n",
       " 'rose': np.int64(1842),\n",
       " 'grave': np.int64(893),\n",
       " 'bslvyl': np.int64(270),\n",
       " 'coffe': np.int64(392),\n",
       " 'somebodi': np.int64(2011),\n",
       " 'high': np.int64(977),\n",
       " 'shit': np.int64(1943),\n",
       " 'shock': np.int64(1945),\n",
       " 'scari': np.int64(1887),\n",
       " 'imagin': np.int64(1054),\n",
       " 'def': np.int64(504),\n",
       " 'somewher': np.int64(2016),\n",
       " 'meal': np.int64(1313),\n",
       " 'hide': np.int64(976),\n",
       " 'book': np.int64(242),\n",
       " 'jo': np.int64(1120),\n",
       " 'friendship': np.int64(780),\n",
       " 'hang': np.int64(934),\n",
       " 'themob': np.int64(2181),\n",
       " 'newest': np.int64(1437),\n",
       " 'game': np.int64(809),\n",
       " 'tone': np.int64(2226),\n",
       " 'gossip': np.int64(879),\n",
       " 'sport': np.int64(2049),\n",
       " 'fit': np.int64(720),\n",
       " 'funki': np.int64(799),\n",
       " 'garag': np.int64(814),\n",
       " 'key': np.int64(1146),\n",
       " 'accept': np.int64(15),\n",
       " 'sister': np.int64(1974),\n",
       " 'clo': np.int64(381),\n",
       " 'lvblefrnd': np.int64(1268),\n",
       " 'jstfrnd': np.int64(1130),\n",
       " 'cutefrnd': np.int64(472),\n",
       " 'lifpartnr': np.int64(1209),\n",
       " 'belovd': np.int64(197),\n",
       " 'swtheart': np.int64(2127),\n",
       " 'bstfrnd': np.int64(271),\n",
       " 'enemi': np.int64(609),\n",
       " 'smart': np.int64(1997),\n",
       " 'weekli': np.int64(2382),\n",
       " 'cs': np.int64(460),\n",
       " 'uz': np.int64(2313),\n",
       " 'definit': np.int64(505),\n",
       " 'normal': np.int64(1456),\n",
       " 'rest': np.int64(1803),\n",
       " 'wot': np.int64(2439),\n",
       " 'lost': np.int64(1246),\n",
       " 'made': np.int64(1275),\n",
       " 'advanc': np.int64(35),\n",
       " 'pongal': np.int64(1602),\n",
       " 'kb': np.int64(1141),\n",
       " 'power': np.int64(1622),\n",
       " 'yoga': np.int64(2487),\n",
       " 'dunno': np.int64(581),\n",
       " 'dude': np.int64(578),\n",
       " 'afraid': np.int64(42),\n",
       " 'decemb': np.int64(498),\n",
       " 'mth': np.int64(1403),\n",
       " 'cake': np.int64(293),\n",
       " 'merri': np.int64(1331),\n",
       " 'christma': np.int64(369),\n",
       " ...}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8dd1d5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': np.int64(233),\n",
       " 'point': np.int64(459),\n",
       " 'avail': np.int64(31),\n",
       " 'great': np.int64(246),\n",
       " 'world': np.int64(680),\n",
       " 'got': np.int64(244),\n",
       " 'wat': np.int64(651),\n",
       " 'ok': np.int64(414),\n",
       " 'lar': np.int64(313),\n",
       " 'joke': np.int64(302),\n",
       " 'wif': np.int64(667),\n",
       " 'free': np.int64(211),\n",
       " 'entri': np.int64(182),\n",
       " 'wkli': np.int64(675),\n",
       " 'win': np.int64(670),\n",
       " 'final': np.int64(198),\n",
       " 'st': np.int64(555),\n",
       " 'may': np.int64(358),\n",
       " 'text': np.int64(581),\n",
       " 'receiv': np.int64(489),\n",
       " 'question': np.int64(478),\n",
       " 'txt': np.int64(619),\n",
       " 'rate': np.int64(482),\n",
       " 'appli': np.int64(25),\n",
       " 'free entri': np.int64(213),\n",
       " 'dun': np.int64(169),\n",
       " 'say': np.int64(510),\n",
       " 'earli': np.int64(171),\n",
       " 'alreadi': np.int64(13),\n",
       " 'think': np.int64(587),\n",
       " 'goe': np.int64(236),\n",
       " 'live': np.int64(335),\n",
       " 'around': np.int64(27),\n",
       " 'though': np.int64(590),\n",
       " 'freemsg': np.int64(215),\n",
       " 'hey': np.int64(272),\n",
       " 'week': np.int64(655),\n",
       " 'word': np.int64(678),\n",
       " 'back': np.int64(39),\n",
       " 'like': np.int64(331),\n",
       " 'fun': np.int64(223),\n",
       " 'still': np.int64(559),\n",
       " 'xxx': np.int64(690),\n",
       " 'send': np.int64(523),\n",
       " 'even': np.int64(184),\n",
       " 'brother': np.int64(60),\n",
       " 'speak': np.int64(553),\n",
       " 'treat': np.int64(612),\n",
       " 'per': np.int64(439),\n",
       " 'set': np.int64(528),\n",
       " 'caller': np.int64(75),\n",
       " 'friend': np.int64(218),\n",
       " 'winner': np.int64(671),\n",
       " 'valu': np.int64(639),\n",
       " 'network': np.int64(393),\n",
       " 'custom': np.int64(133),\n",
       " 'select': np.int64(520),\n",
       " 'prize': np.int64(469),\n",
       " 'claim': np.int64(97),\n",
       " 'call': np.int64(65),\n",
       " 'code': np.int64(106),\n",
       " 'valid': np.int64(637),\n",
       " 'hour': np.int64(283),\n",
       " 'claim call': np.int64(98),\n",
       " 'call claim': np.int64(66),\n",
       " 'mobil': np.int64(371),\n",
       " 'month': np.int64(375),\n",
       " 'updat': np.int64(627),\n",
       " 'latest': np.int64(318),\n",
       " 'colour': np.int64(110),\n",
       " 'camera': np.int64(78),\n",
       " 'co': np.int64(104),\n",
       " 'free call': np.int64(212),\n",
       " 'gonna': np.int64(239),\n",
       " 'home': np.int64(279),\n",
       " 'soon': np.int64(548),\n",
       " 'want': np.int64(648),\n",
       " 'talk': np.int64(573),\n",
       " 'stuff': np.int64(563),\n",
       " 'tonight': np.int64(605),\n",
       " 'enough': np.int64(180),\n",
       " 'today': np.int64(599),\n",
       " 'chanc': np.int64(88),\n",
       " 'cash': np.int64(85),\n",
       " 'pound': np.int64(462),\n",
       " 'cost': np.int64(125),\n",
       " 'day': np.int64(141),\n",
       " 'repli': np.int64(492),\n",
       " 'hl': np.int64(275),\n",
       " 'info': np.int64(296),\n",
       " 'chanc win': np.int64(89),\n",
       " 'urgent': np.int64(631),\n",
       " 'www': np.int64(687),\n",
       " 'net': np.int64(392),\n",
       " 'pobox': np.int64(458),\n",
       " 'txt word': np.int64(621),\n",
       " 'search': np.int64(515),\n",
       " 'right': np.int64(496),\n",
       " 'thank': np.int64(583),\n",
       " 'wont': np.int64(677),\n",
       " 'take': np.int64(571),\n",
       " 'help': np.int64(271),\n",
       " 'wonder': np.int64(676),\n",
       " 'time': np.int64(596),\n",
       " 'date': np.int64(139),\n",
       " 'use': np.int64(634),\n",
       " 'credit': np.int64(129),\n",
       " 'next': np.int64(399),\n",
       " 'messag': np.int64(363),\n",
       " 'http': np.int64(287),\n",
       " 'com': np.int64(111),\n",
       " 'oh': np.int64(413),\n",
       " 'watch': np.int64(653),\n",
       " 'rememb': np.int64(490),\n",
       " 'name': np.int64(386),\n",
       " 'ye': np.int64(692),\n",
       " 'make': np.int64(353),\n",
       " 'fine': np.int64(200),\n",
       " 'way': np.int64(654),\n",
       " 'feel': np.int64(197),\n",
       " 'dont': np.int64(157),\n",
       " 'miss': np.int64(369),\n",
       " 'news': np.int64(398),\n",
       " 'ur': np.int64(628),\n",
       " 'nation': np.int64(387),\n",
       " 'tri': np.int64(613),\n",
       " 'wq': np.int64(685),\n",
       " 'pay': np.int64(437),\n",
       " 'first': np.int64(202),\n",
       " 'da': np.int64(135),\n",
       " 'aft': np.int64(7),\n",
       " 'finish': np.int64(201),\n",
       " 'lunch': np.int64(349),\n",
       " 'lor': np.int64(340),\n",
       " 'ard': np.int64(26),\n",
       " 'smth': np.int64(544),\n",
       " 'alright': np.int64(14),\n",
       " 'meet': np.int64(362),\n",
       " 'eat': np.int64(174),\n",
       " 'realli': np.int64(487),\n",
       " 'tho': np.int64(589),\n",
       " 'get': np.int64(228),\n",
       " 'worri': np.int64(681),\n",
       " 'know': np.int64(308),\n",
       " 'lol': np.int64(337),\n",
       " 'alway': np.int64(16),\n",
       " 'bu': np.int64(62),\n",
       " 'fri': np.int64(216),\n",
       " 'mom': np.int64(373),\n",
       " 'left': np.int64(322),\n",
       " 'dinner': np.int64(154),\n",
       " 'love': np.int64(343),\n",
       " 'amp': np.int64(17),\n",
       " 'car': np.int64(80),\n",
       " 'let': np.int64(326),\n",
       " 'room': np.int64(500),\n",
       " 'let know': np.int64(327),\n",
       " 'work': np.int64(679),\n",
       " 'wait': np.int64(643),\n",
       " 'sure': np.int64(568),\n",
       " 'us': np.int64(633),\n",
       " 'yeah': np.int64(693),\n",
       " 'till': np.int64(595),\n",
       " 'tell': np.int64(576),\n",
       " 'anyth': np.int64(22),\n",
       " 'rington': np.int64(498),\n",
       " 'uk': np.int64(623),\n",
       " 'charg': np.int64(91),\n",
       " 'pleas': np.int64(451),\n",
       " 'confirm': np.int64(118),\n",
       " 'yup': np.int64(699),\n",
       " 'look': np.int64(339),\n",
       " 'msg': np.int64(379),\n",
       " 'nd': np.int64(389),\n",
       " 'lesson': np.int64(325),\n",
       " 'go home': np.int64(234),\n",
       " 'done': np.int64(156),\n",
       " 'see': np.int64(518),\n",
       " 'decid': np.int64(144),\n",
       " 'hello': np.int64(270),\n",
       " 'saturday': np.int64(507),\n",
       " 'tomo': np.int64(602),\n",
       " 'invit': np.int64(299),\n",
       " 'pl': np.int64(445),\n",
       " 'weekend': np.int64(657),\n",
       " 'forget': np.int64(206),\n",
       " 'need': np.int64(391),\n",
       " 'sweet': np.int64(570),\n",
       " 'sm': np.int64(541),\n",
       " 'nokia': np.int64(406),\n",
       " 'camcord': np.int64(76),\n",
       " 'deliveri': np.int64(147),\n",
       " 'tomorrow': np.int64(603),\n",
       " 'pleas call': np.int64(452),\n",
       " 'hope': np.int64(280),\n",
       " 'man': np.int64(354),\n",
       " 'well': np.int64(660),\n",
       " 'lt': np.int64(344),\n",
       " 'gt': np.int64(248),\n",
       " 'lt gt': np.int64(346),\n",
       " 'could': np.int64(126),\n",
       " 'mayb': np.int64(359),\n",
       " 'ask': np.int64(28),\n",
       " 'bit': np.int64(50),\n",
       " 'want go': np.int64(650),\n",
       " 'saw': np.int64(509),\n",
       " 'class': np.int64(100),\n",
       " 'usual': np.int64(635),\n",
       " 'run': np.int64(502),\n",
       " 'half': np.int64(259),\n",
       " 'whole': np.int64(665),\n",
       " 'second': np.int64(516),\n",
       " 'morn': np.int64(376),\n",
       " 'place': np.int64(447),\n",
       " 'never': np.int64(395),\n",
       " 'thought': np.int64(591),\n",
       " 'sinc': np.int64(536),\n",
       " 'best': np.int64(45),\n",
       " 'seem': np.int64(519),\n",
       " 'happi': np.int64(262),\n",
       " 'sorri': np.int64(549),\n",
       " 'give': np.int64(232),\n",
       " 'offer': np.int64(411),\n",
       " 'new': np.int64(396),\n",
       " 'play': np.int64(449),\n",
       " 'correct': np.int64(124),\n",
       " 'end': np.int64(178),\n",
       " 'yesterday': np.int64(695),\n",
       " 'find': np.int64(199),\n",
       " 'congrat': np.int64(119),\n",
       " 'year': np.int64(694),\n",
       " 'special': np.int64(554),\n",
       " 'pass': np.int64(436),\n",
       " 'pm': np.int64(455),\n",
       " 'later': np.int64(317),\n",
       " 'sorri call': np.int64(550),\n",
       " 'call later': np.int64(71),\n",
       " 'reach': np.int64(483),\n",
       " 'pick': np.int64(443),\n",
       " 'move': np.int64(377),\n",
       " 'pain': np.int64(431),\n",
       " 'good': np.int64(240),\n",
       " 'girl': np.int64(231),\n",
       " 'part': np.int64(434),\n",
       " 'check': np.int64(93),\n",
       " 'took': np.int64(606),\n",
       " 'come': np.int64(112),\n",
       " 'doubl': np.int64(159),\n",
       " 'hair': np.int64(258),\n",
       " 'said': np.int64(505),\n",
       " 'nice': np.int64(401),\n",
       " 'follow': np.int64(203),\n",
       " 'mob': np.int64(370),\n",
       " 'award': np.int64(34),\n",
       " 'bonu': np.int64(51),\n",
       " 'song': np.int64(547),\n",
       " 'frnd': np.int64(220),\n",
       " 'trip': np.int64(615),\n",
       " 'di': np.int64(150),\n",
       " 'ur award': np.int64(629),\n",
       " 'hear': np.int64(268),\n",
       " 'lucki': np.int64(348),\n",
       " 'save': np.int64(508),\n",
       " 'money': np.int64(374),\n",
       " 'hi': np.int64(273),\n",
       " 'babe': np.int64(37),\n",
       " 'im': np.int64(294),\n",
       " 'wanna': np.int64(647),\n",
       " 'someth': np.int64(546),\n",
       " 'xx': np.int64(689),\n",
       " 'that': np.int64(585),\n",
       " 'cool': np.int64(123),\n",
       " 'peopl': np.int64(438),\n",
       " 'much': np.int64(382),\n",
       " 'pa': np.int64(430),\n",
       " 'oper': np.int64(422),\n",
       " 'job': np.int64(300),\n",
       " 'ah': np.int64(10),\n",
       " 'stop': np.int64(560),\n",
       " 'real': np.int64(486),\n",
       " 'yo': np.int64(697),\n",
       " 'ticket': np.int64(593),\n",
       " 'one': np.int64(419),\n",
       " 'start': np.int64(556),\n",
       " 'came': np.int64(77),\n",
       " 'bed': np.int64(43),\n",
       " 'download': np.int64(160),\n",
       " 'wen': np.int64(661),\n",
       " 'close': np.int64(102),\n",
       " 'anoth': np.int64(19),\n",
       " 'night': np.int64(403),\n",
       " 'late': np.int64(316),\n",
       " 'afternoon': np.int64(8),\n",
       " 'mean': np.int64(360),\n",
       " 'smile': np.int64(542),\n",
       " 'rain': np.int64(481),\n",
       " 'hurt': np.int64(289),\n",
       " 'someon': np.int64(545),\n",
       " 'servic': np.int64(527),\n",
       " 'guarante': np.int64(251),\n",
       " 'call custom': np.int64(67),\n",
       " 'custom servic': np.int64(134),\n",
       " 'cash prize': np.int64(86),\n",
       " 'havent': np.int64(266),\n",
       " 'plan': np.int64(448),\n",
       " 'buy': np.int64(64),\n",
       " 'show': np.int64(533),\n",
       " 'collect': np.int64(108),\n",
       " 'movi': np.int64(378),\n",
       " 'abt': np.int64(1),\n",
       " 'wk': np.int64(674),\n",
       " 'forgot': np.int64(207),\n",
       " 'caus': np.int64(87),\n",
       " 'prob': np.int64(472),\n",
       " 'noth': np.int64(408),\n",
       " 'els': np.int64(176),\n",
       " 'okay': np.int64(416),\n",
       " 'price': np.int64(465),\n",
       " 'long': np.int64(338),\n",
       " 'gone': np.int64(238),\n",
       " 'drive': np.int64(165),\n",
       " 'test': np.int64(580),\n",
       " 'yet': np.int64(696),\n",
       " 'guess': np.int64(254),\n",
       " 'chang': np.int64(90),\n",
       " 'life': np.int64(329),\n",
       " 'lot': np.int64(342),\n",
       " 'dear': np.int64(143),\n",
       " 'wish': np.int64(672),\n",
       " 'birthday': np.int64(49),\n",
       " 'aight': np.int64(11),\n",
       " 'hit': np.int64(274),\n",
       " 'would': np.int64(684),\n",
       " 'address': np.int64(6),\n",
       " 'comput': np.int64(117),\n",
       " 'old': np.int64(418),\n",
       " 'better': np.int64(46),\n",
       " 'busi': np.int64(63),\n",
       " 'thing': np.int64(586),\n",
       " 'contact': np.int64(121),\n",
       " 'last': np.int64(314),\n",
       " 'draw': np.int64(161),\n",
       " 'hr': np.int64(286),\n",
       " 'ppm': np.int64(463),\n",
       " 'tri contact': np.int64(614),\n",
       " 'draw show': np.int64(162),\n",
       " 'show prize': np.int64(534),\n",
       " 'prize guarante': np.int64(471),\n",
       " 'guarante call': np.int64(252),\n",
       " 'valid hr': np.int64(638),\n",
       " 'anyway': np.int64(24),\n",
       " 'juz': np.int64(304),\n",
       " 'haha': np.int64(257),\n",
       " 'happen': np.int64(261),\n",
       " 'enter': np.int64(181),\n",
       " 'went': np.int64(662),\n",
       " 'holiday': np.int64(278),\n",
       " 'min': np.int64(365),\n",
       " 'select receiv': np.int64(521),\n",
       " 'must': np.int64(385),\n",
       " 'friday': np.int64(217),\n",
       " 'hmm': np.int64(276),\n",
       " 'uncl': np.int64(624),\n",
       " 'inform': np.int64(297),\n",
       " 'school': np.int64(512),\n",
       " 'food': np.int64(205),\n",
       " 'privat': np.int64(467),\n",
       " 'account': np.int64(2),\n",
       " 'statement': np.int64(557),\n",
       " 'identifi': np.int64(291),\n",
       " 'expir': np.int64(191),\n",
       " 'privat account': np.int64(468),\n",
       " 'account statement': np.int64(3),\n",
       " 'call identifi': np.int64(68),\n",
       " 'identifi code': np.int64(292),\n",
       " 'code expir': np.int64(107),\n",
       " 'landlin': np.int64(312),\n",
       " 'box': np.int64(55),\n",
       " 'urgent mobil': np.int64(632),\n",
       " 'call landlin': np.int64(70),\n",
       " 'number': np.int64(410),\n",
       " 'match': np.int64(356),\n",
       " 'mu': np.int64(381),\n",
       " 'wat time': np.int64(652),\n",
       " 'sent': np.int64(526),\n",
       " 'answer': np.int64(20),\n",
       " 'quiz': np.int64(480),\n",
       " 'top': np.int64(607),\n",
       " 'player': np.int64(450),\n",
       " 'dog': np.int64(155),\n",
       " 'join': np.int64(301),\n",
       " 'bt': np.int64(61),\n",
       " 'nt': np.int64(409),\n",
       " 'ur mob': np.int64(630),\n",
       " 'haf': np.int64(256),\n",
       " 'chat': np.int64(92),\n",
       " 'age': np.int64(9),\n",
       " 'yr': np.int64(698),\n",
       " 'type': np.int64(622),\n",
       " 'sir': np.int64(537),\n",
       " 'mail': np.int64(352),\n",
       " 'tire': np.int64(597),\n",
       " 'littl': np.int64(334),\n",
       " 'person': np.int64(440),\n",
       " 'coz': np.int64(128),\n",
       " 'heart': np.int64(269),\n",
       " 'gud': np.int64(253),\n",
       " 'ni': np.int64(400),\n",
       " 'open': np.int64(421),\n",
       " 'ya': np.int64(691),\n",
       " 'what': np.int64(663),\n",
       " 'sexi': np.int64(529),\n",
       " 'luv': np.int64(350),\n",
       " 'ltd': np.int64(347),\n",
       " 'hard': np.int64(264),\n",
       " 'thk': np.int64(588),\n",
       " 'dream': np.int64(163),\n",
       " 'without': np.int64(673),\n",
       " 'tv': np.int64(617),\n",
       " 'leav': np.int64(321),\n",
       " 'hous': np.int64(284),\n",
       " 'boy': np.int64(56),\n",
       " 'new year': np.int64(397),\n",
       " 'keep': np.int64(305),\n",
       " 'everyon': np.int64(188),\n",
       " 'parent': np.int64(432),\n",
       " 'hand': np.int64(260),\n",
       " 'send stop': np.int64(525),\n",
       " 'order': np.int64(426),\n",
       " 'content': np.int64(122),\n",
       " 'fanci': np.int64(194),\n",
       " 'complet': np.int64(116),\n",
       " 'also': np.int64(15),\n",
       " 'liao': np.int64(328),\n",
       " 'cant': np.int64(79),\n",
       " 'believ': np.int64(44),\n",
       " 'ill': np.int64(293),\n",
       " 'bath': np.int64(41),\n",
       " 'carlo': np.int64(83),\n",
       " 'stay': np.int64(558),\n",
       " 'til': np.int64(594),\n",
       " 'smoke': np.int64(543),\n",
       " 'worth': np.int64(682),\n",
       " 'log': np.int64(336),\n",
       " 'studi': np.int64(562),\n",
       " 'gr': np.int64(245),\n",
       " 'guy': np.int64(255),\n",
       " 'boytoy': np.int64(57),\n",
       " 'get back': np.int64(229),\n",
       " 'awesom': np.int64(36),\n",
       " 'minut': np.int64(368),\n",
       " 'xma': np.int64(688),\n",
       " 'ju': np.int64(303),\n",
       " 'si': np.int64(535),\n",
       " 'th': np.int64(582),\n",
       " 'co uk': np.int64(105),\n",
       " 'touch': np.int64(609),\n",
       " 'cours': np.int64(127),\n",
       " 'abl': np.int64(0),\n",
       " 'everi': np.int64(186),\n",
       " 'hav': np.int64(265),\n",
       " 'nice day': np.int64(402),\n",
       " 'stori': np.int64(561),\n",
       " 'tmr': np.int64(598),\n",
       " 'found': np.int64(209),\n",
       " 'darlin': np.int64(137),\n",
       " 'colleg': np.int64(109),\n",
       " 'decim': np.int64(145),\n",
       " 'id': np.int64(290),\n",
       " 'lt decim': np.int64(345),\n",
       " 'decim gt': np.int64(146),\n",
       " 'goodmorn': np.int64(243),\n",
       " 'sleep': np.int64(540),\n",
       " 'ga': np.int64(224),\n",
       " 'dat': np.int64(138),\n",
       " 'oso': np.int64(428),\n",
       " 'oredi': np.int64(427),\n",
       " 'bill': np.int64(48),\n",
       " 'big': np.int64(47),\n",
       " 'readi': np.int64(485),\n",
       " 'break': np.int64(58),\n",
       " 'noe': np.int64(405),\n",
       " 'leh': np.int64(323),\n",
       " 'sound': np.int64(552),\n",
       " 'head': np.int64(267),\n",
       " 'easi': np.int64(173),\n",
       " 'exam': np.int64(190),\n",
       " 'import': np.int64(295),\n",
       " 'shop': np.int64(532),\n",
       " 'nite': np.int64(404),\n",
       " 'tc': np.int64(574),\n",
       " 'optout': np.int64(424),\n",
       " 'gbp': np.int64(226),\n",
       " 'compani': np.int64(115),\n",
       " 'po': np.int64(456),\n",
       " 'good morn': np.int64(241),\n",
       " 'walk': np.int64(645),\n",
       " 'die': np.int64(152),\n",
       " 'wil': np.int64(669),\n",
       " 'lose': np.int64(341),\n",
       " 'secret': np.int64(517),\n",
       " 'reveal': np.int64(495),\n",
       " 'case': np.int64(84),\n",
       " 'tel': np.int64(575),\n",
       " 'meant': np.int64(361),\n",
       " 'told': np.int64(601),\n",
       " 'face': np.int64(192),\n",
       " 'fr': np.int64(210),\n",
       " 'thanx': np.int64(584),\n",
       " 'everyth': np.int64(189),\n",
       " 'didnt': np.int64(151),\n",
       " 'wake': np.int64(644),\n",
       " 'good night': np.int64(242),\n",
       " 'congratul': np.int64(120),\n",
       " 'voucher': np.int64(642),\n",
       " 'gift': np.int64(230),\n",
       " 'music': np.int64(384),\n",
       " 'hold': np.int64(277),\n",
       " 'angri': np.int64(18),\n",
       " 'wid': np.int64(666),\n",
       " 'true': np.int64(616),\n",
       " 'care': np.int64(82),\n",
       " 'video': np.int64(640),\n",
       " 'anytim': np.int64(23),\n",
       " 'repli call': np.int64(493),\n",
       " 'park': np.int64(433),\n",
       " 'ring': np.int64(497),\n",
       " 'hot': np.int64(282),\n",
       " 'unsubscrib': np.int64(626),\n",
       " 'club': np.int64(103),\n",
       " 'choos': np.int64(96),\n",
       " 'po box': np.int64(457),\n",
       " 'sort': np.int64(551),\n",
       " 'might': np.int64(364),\n",
       " 'full': np.int64(222),\n",
       " 'far': np.int64(195),\n",
       " 'oki': np.int64(417),\n",
       " 'last night': np.int64(315),\n",
       " 'babi': np.int64(38),\n",
       " 'fone': np.int64(204),\n",
       " 'shall': np.int64(530),\n",
       " 'phone': np.int64(441),\n",
       " 'card': np.int64(81),\n",
       " 'plz': np.int64(454),\n",
       " 'pick phone': np.int64(444),\n",
       " 'pl send': np.int64(446),\n",
       " 'send messag': np.int64(524),\n",
       " 'shit': np.int64(531),\n",
       " 'book': np.int64(52),\n",
       " 'friendship': np.int64(219),\n",
       " 'game': np.int64(225),\n",
       " 'tone': np.int64(604),\n",
       " 'sister': np.int64(538),\n",
       " 'weekli': np.int64(658),\n",
       " 'cs': np.int64(130),\n",
       " 'wot': np.int64(683),\n",
       " 'made': np.int64(351),\n",
       " 'great day': np.int64(247),\n",
       " 'dunno': np.int64(170),\n",
       " 'dude': np.int64(168),\n",
       " 'mth': np.int64(380),\n",
       " 'kiss': np.int64(307),\n",
       " 'problem': np.int64(474),\n",
       " 'read': np.int64(484),\n",
       " 'light': np.int64(330),\n",
       " 'return': np.int64(494),\n",
       " 'line': np.int64(332),\n",
       " 'valentin': np.int64(636),\n",
       " 'post': np.int64(461),\n",
       " 'interest': np.int64(298),\n",
       " 'two': np.int64(618),\n",
       " 'ever': np.int64(185),\n",
       " 'current': np.int64(132),\n",
       " 'suit': np.int64(565),\n",
       " 'land': np.int64(309),\n",
       " 'row': np.int64(501),\n",
       " 'suit land': np.int64(566),\n",
       " 'land row': np.int64(311),\n",
       " 'chikku': np.int64(95),\n",
       " 'forward': np.int64(208),\n",
       " 'take care': np.int64(572),\n",
       " 'orang': np.int64(425),\n",
       " 'mobileupd': np.int64(372),\n",
       " 'call mobileupd': np.int64(72),\n",
       " 'call optout': np.int64(73),\n",
       " 'gt min': np.int64(250),\n",
       " 'bring': np.int64(59),\n",
       " 'project': np.int64(475),\n",
       " 'quit': np.int64(479),\n",
       " 'reason': np.int64(488),\n",
       " 'huh': np.int64(288),\n",
       " 'sat': np.int64(506),\n",
       " 'offic': np.int64(412),\n",
       " 'bout': np.int64(54),\n",
       " 'actual': np.int64(4),\n",
       " 'put': np.int64(477),\n",
       " 'god': np.int64(235),\n",
       " 'poli': np.int64(460),\n",
       " 'txt stop': np.int64(620),\n",
       " 'drink': np.int64(164),\n",
       " 'den': np.int64(148),\n",
       " 'date servic': np.int64(140),\n",
       " 'eve': np.int64(183),\n",
       " 'ad': np.int64(5),\n",
       " 'call land': np.int64(69),\n",
       " 'land line': np.int64(310),\n",
       " 'claim valid': np.int64(99),\n",
       " 'mind': np.int64(366),\n",
       " 'fuck': np.int64(221),\n",
       " 'gt lt': np.int64(249),\n",
       " 'ten': np.int64(578),\n",
       " 'gd': np.int64(227),\n",
       " 'tot': np.int64(608),\n",
       " 'hope good': np.int64(281),\n",
       " 'detail': np.int64(149),\n",
       " 'welcom': np.int64(659),\n",
       " 'free text': np.int64(214),\n",
       " 'beauti': np.int64(42),\n",
       " 'kind': np.int64(306),\n",
       " 'bad': np.int64(40),\n",
       " 'differ': np.int64(153),\n",
       " 'opt': np.int64(423),\n",
       " 'princess': np.int64(466),\n",
       " 'enjoy': np.int64(179),\n",
       " 'mani': np.int64(355),\n",
       " 'sae': np.int64(504),\n",
       " 'scream': np.int64(513),\n",
       " 'remov': np.int64(491),\n",
       " 'cum': np.int64(131),\n",
       " 'term': np.int64(579),\n",
       " 'visit': np.int64(641),\n",
       " 'nope': np.int64(407),\n",
       " 'either': np.int64(175),\n",
       " 'prize claim': np.int64(470),\n",
       " 'bore': np.int64(53),\n",
       " 'outsid': np.int64(429),\n",
       " 'attempt': np.int64(29),\n",
       " 'nd attempt': np.int64(390),\n",
       " 'attempt contact': np.int64(30),\n",
       " 'sub': np.int64(564),\n",
       " 'pretti': np.int64(464),\n",
       " 'sea': np.int64(514),\n",
       " 'probabl': np.int64(473),\n",
       " 'listen': np.int64(333),\n",
       " 'mine': np.int64(367),\n",
       " 'onlin': np.int64(420),\n",
       " 'pic': np.int64(442),\n",
       " 'fast': np.int64(196),\n",
       " 'whatev': np.int64(664),\n",
       " 'mum': np.int64(383),\n",
       " 'sch': np.int64(511),\n",
       " 'clean': np.int64(101),\n",
       " 'wife': np.int64(668),\n",
       " 'train': np.int64(611),\n",
       " 'ok lor': np.int64(415),\n",
       " 'neva': np.int64(394),\n",
       " 'want come': np.int64(649),\n",
       " 'famili': np.int64(193),\n",
       " 'togeth': np.int64(600),\n",
       " 'pub': np.int64(476),\n",
       " 'dad': np.int64(136),\n",
       " 'email': np.int64(177),\n",
       " 'town': np.int64(610),\n",
       " 'drug': np.int64(167),\n",
       " 'sun': np.int64(567),\n",
       " 'de': np.int64(142),\n",
       " 'laugh': np.int64(319),\n",
       " 'everi week': np.int64(187),\n",
       " 'come home': np.int64(114),\n",
       " 'away': np.int64(35),\n",
       " 'sit': np.int64(539),\n",
       " 'sell': np.int64(522),\n",
       " 'rite': np.int64(499),\n",
       " 'anyon': np.int64(21),\n",
       " 'happi new': np.int64(263),\n",
       " 'goin': np.int64(237),\n",
       " 'nation rate': np.int64(388),\n",
       " 'mate': np.int64(357),\n",
       " 'week txt': np.int64(656),\n",
       " 'tell ur': np.int64(577),\n",
       " 'understand': np.int64(625),\n",
       " 'await': np.int64(32),\n",
       " 'await collect': np.int64(33),\n",
       " 'wan': np.int64(646),\n",
       " 'drop': np.int64(166),\n",
       " 'dont know': np.int64(158),\n",
       " 'sad': np.int64(503),\n",
       " 'plu': np.int64(453),\n",
       " 'wrong': np.int64(686),\n",
       " 'least': np.int64(320),\n",
       " 'come back': np.int64(113),\n",
       " 'earlier': np.int64(172),\n",
       " 'parti': np.int64(435),\n",
       " 'surpris': np.int64(569),\n",
       " 'chennai': np.int64(94),\n",
       " 'tht': np.int64(592),\n",
       " 'call per': np.int64(74),\n",
       " 'alon': np.int64(12),\n",
       " 'how': np.int64(285),\n",
       " 'lei': np.int64(324)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=700,binary=True,ngram_range=(1,2))                      #maxfeatures indicate to pick the top2500 most occuring words, rest values are not required\n",
    "X = cv.fit_transform(corpus).toarray()   \n",
    "cv.vocabulary_\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5d91b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "#object\n",
    "wordlemmatize = WordNetLemmatizer()\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in range(0,len(text)):\n",
    "    review = re.sub('[^a-zA-z]',' ',text['Message'][i])          #ro access each rows in a column we use text[message][i]\n",
    "    review = review.lower()\n",
    "    review = review.split()           #splits sentences into rows\n",
    "    review = [wordlemmatize.lemmatize(word) for word in review if word not in stopwords.words('english')]\n",
    "    review = ' '.join(review)             #words are joined to form sentences\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9be93172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = CountVectorizer(max_features=100)\n",
    "X = tf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4844516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(edgeitems=30,linewidth=100000,formatter = dict(float = lambda x: \"%.3g\" % x ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04959fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ..., 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ..., 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ..., 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], shape=(5573, 100))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb38426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c1a1c6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
       "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
       "1          2    15647311      Hill  ...               1       112542.58      0\n",
       "2          3    15619304      Onio  ...               0       113931.57      1\n",
       "3          4    15701354      Boni  ...               0        93826.63      0\n",
       "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset\n",
    "data = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "data.head()                     #displays the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "08accb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  ...  IsActiveMember  EstimatedSalary  Exited\n",
       "0             619    France  Female  ...               1        101348.88       1\n",
       "1             608     Spain  Female  ...               1        112542.58       0\n",
       "2             502    France  Female  ...               0        113931.57       1\n",
       "3             699    France  Female  ...               0         93826.63       0\n",
       "4             850     Spain  Female  ...               1         79084.10       0\n",
       "...           ...       ...     ...  ...             ...              ...     ...\n",
       "9995          771    France    Male  ...               0         96270.64       0\n",
       "9996          516    France    Male  ...               1        101699.77       0\n",
       "9997          709    France  Female  ...               1         42085.58       1\n",
       "9998          772   Germany    Male  ...               0         92888.52       1\n",
       "9999          792    France  Female  ...               0         38190.78       0\n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data preprocessing\n",
    "data = data.drop(['RowNumber','CustomerId','Surname'],axis=1)       #dropiing irelevant columns from data, axis =1 means columnwise\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "17140abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  ...  IsActiveMember  EstimatedSalary  Exited\n",
       "0             619    France       0  ...               1        101348.88       1\n",
       "1             608     Spain       0  ...               1        112542.58       0\n",
       "2             502    France       0  ...               0        113931.57       1\n",
       "3             699    France       0  ...               0         93826.63       0\n",
       "4             850     Spain       0  ...               1         79084.10       0\n",
       "...           ...       ...     ...  ...             ...              ...     ...\n",
       "9995          771    France       1  ...               0         96270.64       0\n",
       "9996          516    France       1  ...               1        101699.77       0\n",
       "9997          709    France       0  ...               1         42085.58       1\n",
       "9998          772   Germany       1  ...               0         92888.52       1\n",
       "9999          792    France       0  ...               0         38190.78       0\n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode categorical variables\n",
    "label_encoder_gender = LabelEncoder()                     #This is used from sklearn, used to encode values as 0 or 1 in gender as it has only 2 values\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])      #fit_transform studies the values and transforms here into numerical value\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bd5330a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 10000 stored elements and shape (10000, 3)>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder_geo = OneHotEncoder()\n",
    "\n",
    "geo_encoder = one_hot_encoder_geo.fit_transform(data[['Geography']])\n",
    "geo_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f6165282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]], shape=(10000, 3))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now convert it into a matrix\n",
    "geo_encoder.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5378fe7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Geography_France', 'Geography_Germany', 'Geography_Spain'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder_geo.get_feature_names_out(['Geography'])    #This allows us to see which all values has been OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ecbf9948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Geography_France  Geography_Germany  Geography_Spain\n",
       "0                  1.0                0.0              0.0\n",
       "1                  0.0                0.0              1.0\n",
       "2                  1.0                0.0              0.0\n",
       "3                  1.0                0.0              0.0\n",
       "4                  0.0                0.0              1.0\n",
       "...                ...                ...              ...\n",
       "9995               1.0                0.0              0.0\n",
       "9996               1.0                0.0              0.0\n",
       "9997               1.0                0.0              0.0\n",
       "9998               0.0                1.0              0.0\n",
       "9999               1.0                0.0              0.0\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_encoded_df = pd.DataFrame(geo_encoder.toarray(),columns=one_hot_encoder_geo.get_feature_names_out(['Geography']) )\n",
    "geo_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c7c6874f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  ...  Geography_Germany  Geography_Spain\n",
       "0          619       0  ...                0.0              0.0\n",
       "1          608       0  ...                0.0              1.0\n",
       "2          502       0  ...                0.0              0.0\n",
       "3          699       0  ...                0.0              0.0\n",
       "4          850       0  ...                0.0              1.0\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine onehot encoded values with original data\n",
    "\n",
    "data = pd.concat([data.drop('Geography',axis =1),geo_encoded_df],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "153bb08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save encoders and scalars cerated in a pickle file\n",
    "\n",
    "with open('label_encoder_gender.pkl','wb') as file:    #Creates a new .pkl file\n",
    "    pickle.dump(label_encoder_gender,file)\n",
    "with open('one_hot_encoder_geo.pkl','wb') as file:\n",
    "    pickle.dump(one_hot_encoder_geo,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4251b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide dataset into dependent and independent features\n",
    "\n",
    "X = data.drop('Exited',axis=1)  #Independent\n",
    "Y = data['Exited']   #Dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c295fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)\n",
    "\n",
    "#Scale these features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "26fff399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35649971,  0.91324755, -0.6557859 , ...,  1.00150113,\n",
       "        -0.57946723, -0.57638802],\n",
       "       [-0.20389777,  0.91324755,  0.29493847, ..., -0.99850112,\n",
       "         1.72572313, -0.57638802],\n",
       "       [-0.96147213,  0.91324755, -1.41636539, ..., -0.99850112,\n",
       "        -0.57946723,  1.73494238],\n",
       "       ...,\n",
       "       [ 0.86500853, -1.09499335, -0.08535128, ...,  1.00150113,\n",
       "        -0.57946723, -0.57638802],\n",
       "       [ 0.15932282,  0.91324755,  0.3900109 , ...,  1.00150113,\n",
       "        -0.57946723, -0.57638802],\n",
       "       [ 0.47065475,  0.91324755,  1.15059039, ..., -0.99850112,\n",
       "         1.72572313, -0.57638802]], shape=(8000, 12))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "38b68670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57749609,  0.91324755, -0.6557859 , ..., -0.99850112,\n",
       "         1.72572313, -0.57638802],\n",
       "       [-0.29729735,  0.91324755,  0.3900109 , ...,  1.00150113,\n",
       "        -0.57946723, -0.57638802],\n",
       "       [-0.52560743, -1.09499335,  0.48508334, ..., -0.99850112,\n",
       "        -0.57946723,  1.73494238],\n",
       "       ...,\n",
       "       [ 0.81311987, -1.09499335,  0.77030065, ...,  1.00150113,\n",
       "        -0.57946723, -0.57638802],\n",
       "       [ 0.41876609,  0.91324755, -0.94100321, ...,  1.00150113,\n",
       "        -0.57946723, -0.57638802],\n",
       "       [-0.24540869,  0.91324755,  0.00972116, ..., -0.99850112,\n",
       "         1.72572313, -0.57638802]], shape=(2000, 12))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "df5144a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to pickle file\n",
    "\n",
    "with open('scaler.pkl','wb') as file:\n",
    "    pickle.dump(scaler,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1e19f780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  ...  Geography_Germany  Geography_Spain\n",
       "0             619       0  ...                0.0              0.0\n",
       "1             608       0  ...                0.0              1.0\n",
       "2             502       0  ...                0.0              0.0\n",
       "3             699       0  ...                0.0              0.0\n",
       "4             850       0  ...                0.0              1.0\n",
       "...           ...     ...  ...                ...              ...\n",
       "9995          771       1  ...                0.0              0.0\n",
       "9996          516       1  ...                0.0              0.0\n",
       "9997          709       0  ...                0.0              0.0\n",
       "9998          772       1  ...                1.0              0.0\n",
       "9999          792       0  ...                0.0              0.0\n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8c723d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9b2fb222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Build the ANN Model\n",
    "\n",
    "model = Sequential(\n",
    "    [      #First hidden layer connected to input\n",
    "        Dense(64,activation='relu',input_shape = (X_train.shape[1],)),  #X_train is used to train the data and shape[1],blank = number of features per sample. \",blank\" takes all features\n",
    "        Dense(32,activation='relu'), #HL2\n",
    "        Dense(1,activation='sigmoid')  #Output layer\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ceb48012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m832\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_11 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m33\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,945</span> (11.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,945\u001b[0m (11.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,945</span> (11.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,945\u001b[0m (11.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2bf42ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model 1\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss='binary_crossentropy',metrics=['accuracy'])        #for binary classification we use this and for multilevel we use sparse_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0d6aa8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model 2\n",
    "import tensorflow\n",
    "opt = tensorflow.keras.optimizers.Adam(learning_rate=0.01)                  #can define our own learning rate here previous case takes a default value\n",
    "loss_model = tensorflow.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model.compile(optimizer=opt,loss=loss_model,metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e5ef1953",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup tensor board\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "log_directory = \"logs/fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorflow_callback = TensorBoard(log_dir=log_directory,histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "85cc1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Early Stopping\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True)  #be pateint for atleast 5 epochs and then do Early Stopping if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "29c5ff3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8361 - loss: 0.3943 - val_accuracy: 0.8495 - val_loss: 0.3570\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8533 - loss: 0.3544 - val_accuracy: 0.8615 - val_loss: 0.3377\n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8560 - loss: 0.3467 - val_accuracy: 0.8590 - val_loss: 0.3450\n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.3432 - val_accuracy: 0.8590 - val_loss: 0.3458\n",
      "Epoch 5/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.3430 - val_accuracy: 0.8525 - val_loss: 0.3458\n",
      "Epoch 6/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.3374 - val_accuracy: 0.8570 - val_loss: 0.3421\n",
      "Epoch 7/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8644 - loss: 0.3362 - val_accuracy: 0.8590 - val_loss: 0.3447\n",
      "Epoch 8/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8621 - loss: 0.3359 - val_accuracy: 0.8600 - val_loss: 0.3472\n",
      "Epoch 9/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8645 - loss: 0.3325 - val_accuracy: 0.8595 - val_loss: 0.3513\n",
      "Epoch 10/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8681 - loss: 0.3291 - val_accuracy: 0.8545 - val_loss: 0.3664\n",
      "Epoch 11/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8658 - loss: 0.3278 - val_accuracy: 0.8540 - val_loss: 0.3573\n",
      "Epoch 12/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8648 - loss: 0.3273 - val_accuracy: 0.8590 - val_loss: 0.3499\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "history = model.fit(\n",
    "    X_train,Y_train,validation_data=(X_test,Y_test),epochs=100,\n",
    "    callbacks = [tensorflow_callback,early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b859ea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#saving this model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a659ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load TensorBoard Extension\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64cc1d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 24884), started 0:01:02 ago. (Use '!kill 24884' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1deb07198d9e57e7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1deb07198d9e57e7\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fe6057ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#load the trained model, pickle file, scalar, OHE\n",
    "model = load_model('model.h5')\n",
    "\n",
    "#load the encoder and scalar\n",
    "with open('one_hot_encoder_geo.pkl','rb') as file:\n",
    "    one_hot_encoder_geo = pickle.load(file)\n",
    "with open('label_encoder_gender.pkl','rb') as file:\n",
    "    label_encoder_gender = pickle.load(file)\n",
    "with open('scaler.pkl','rb') as file:\n",
    "    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "47872dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input data\n",
    "input_data = {\n",
    "    'CreditScore': 600,\n",
    "    'Geography': 'France',\n",
    "    'Gender': 'Male',\n",
    "    'Age': 40,\n",
    "    'Tenure': 3,\n",
    "    'Balance': 60000,\n",
    "    'NumOfProducts': 2,\n",
    "    'HasCrCard': 1,\n",
    "    'IsActiveMember': 1,\n",
    "    'EstimatedSalary': 50000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7815000a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Geography_France  Geography_Germany  Geography_Spain\n",
       "0               1.0                0.0              0.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "geo_encoder = one_hot_encoder_geo.transform([[input_data['Geography']]]).toarray()  #OHE requires data in 2D, that is why 2 square brackets\n",
    "df_encoded_geo = pd.DataFrame(geo_encoder,columns=one_hot_encoder_geo.get_feature_names_out(['Geography']))\n",
    "df_encoded_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3a380aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>60000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography Gender  ...  HasCrCard  IsActiveMember  EstimatedSalary\n",
       "0          600    France   Male  ...          1               1            50000\n",
       "\n",
       "[1 rows x 10 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df = pd.DataFrame([input_data])              #converting a dict to table\n",
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dc379ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>60000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  ...  HasCrCard  IsActiveMember  EstimatedSalary\n",
       "0          600    France       1  ...          1               1            50000\n",
       "\n",
       "[1 rows x 10 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df['Gender'] = label_encoder_gender.transform(input_df['Gender'])\n",
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ba36494c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>60000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  ...  Geography_Germany  Geography_Spain\n",
       "0          600       1  ...                0.0              0.0\n",
       "\n",
       "[1 rows x 12 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concat of OHE into input data\n",
    "\n",
    "input_df = pd.concat([input_df.drop(\"Geography\",axis=1),df_encoded_geo],axis=1)  #Whenever you want to concatenate multiple DataFrames, wrap them in a list\n",
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c061c77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.53598516,  0.91324755,  0.10479359, -0.69539349, -0.25781119,\n",
       "         0.80843615,  0.64920267,  0.97481699, -0.87683221,  1.00150113,\n",
       "        -0.57946723, -0.57638802]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concvertng into scalar values\n",
    "input_scaled = scaler.transform(input_df)\n",
    "input_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cbb9091f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01597918]], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(input_scaled)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0a0154a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.01597918)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_prob = prediction[0][0]\n",
    "prediction_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "57cf043d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The customer is not likely to churn\n"
     ]
    }
   ],
   "source": [
    "if prediction_prob > 0.5:\n",
    "    print('The customer is likely to churn')\n",
    "else:\n",
    "    print('The customer is not likely to churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "16fa92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word Embeddings\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\n",
    "sent = ['a glass of milk',\n",
    "        'the cup of tea',\n",
    "        'I am a good boy',\n",
    "        'the glass of juice'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ee0cfe40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a glass of milk', 'the cup of tea', 'I am a good boy', 'the glass of juice']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "cb0ffe26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3638, 9936, 1036, 2076],\n",
       " [5094, 1395, 1036, 2157],\n",
       " [985, 2279, 3638, 1962, 4485],\n",
       " [5094, 9936, 1036, 5990]]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_size = 10000\n",
    "one_hot_repr = [one_hot(words,voc_size) for words in sent]\n",
    "one_hot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "eeed6c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word Embeddings\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9915ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_length = 8\n",
    "embedded_docs = pad_sequences(one_hot_repr,padding='pre',maxlen=sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "03c24e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0 3638 9936 1036 2076]\n",
      " [   0    0    0    0 5094 1395 1036 2157]\n",
      " [   0    0    0  985 2279 3638 1962 4485]\n",
      " [   0    0    0    0 5094 9936 1036 5990]]\n"
     ]
    }
   ],
   "source": [
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d2f0f8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Feature Representation\n",
    "dim =10\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size,dim,input_length=sent_length)) #Adding a Embedding Layer to our model\n",
    "#train\n",
    "model.compile('adam','mse')   #adam is the optimizer and loss function is mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f2a16b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,000</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚       \u001b[38;5;34m100,000\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,000</span> (390.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m100,000\u001b[0m (390.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,000</span> (390.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,000\u001b[0m (390.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "452bf66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.02646324, -0.01420127,  0.01776257, -0.01645806,\n",
       "          0.01392288, -0.03266357,  0.03534045, -0.00140784,\n",
       "          0.00197377, -0.01842197],\n",
       "        [ 0.02646324, -0.01420127,  0.01776257, -0.01645806,\n",
       "          0.01392288, -0.03266357,  0.03534045, -0.00140784,\n",
       "          0.00197377, -0.01842197],\n",
       "        [ 0.02646324, -0.01420127,  0.01776257, -0.01645806,\n",
       "          0.01392288, -0.03266357,  0.03534045, -0.00140784,\n",
       "          0.00197377, -0.01842197],\n",
       "        [ 0.02646324, -0.01420127,  0.01776257, -0.01645806,\n",
       "          0.01392288, -0.03266357,  0.03534045, -0.00140784,\n",
       "          0.00197377, -0.01842197],\n",
       "        [-0.01323009,  0.01165577, -0.04552482, -0.00890896,\n",
       "         -0.02304286,  0.02990704,  0.01552539, -0.01223302,\n",
       "         -0.04284222,  0.03085187],\n",
       "        [-0.04864476, -0.01736289,  0.04796194,  0.02112206,\n",
       "          0.04908483, -0.00840663,  0.00845854,  0.02431414,\n",
       "          0.01154106, -0.0079723 ],\n",
       "        [-0.01527905,  0.04388886, -0.00275927,  0.03916239,\n",
       "          0.01914421,  0.04669264, -0.00490501,  0.01607584,\n",
       "          0.03569106, -0.03500973],\n",
       "        [-0.03903127,  0.00724834, -0.01212536,  0.02508156,\n",
       "          0.03207776,  0.02604279,  0.0392719 , -0.0061985 ,\n",
       "         -0.02356674, -0.0156711 ]],\n",
       "\n",
       "       [[ 0.02646324, -0.01420127,  0.01776257, -0.01645806,\n",
       "          0.01392288, -0.03266357,  0.03534045, -0.00140784,\n",
       "          0.00197377, -0.01842197],\n",
       "        [ 0.02646324, -0.01420127,  0.01776257, -0.01645806,\n",
       "          0.01392288, -0.03266357,  0.03534045, -0.00140784,\n",
       "          0.00197377, -0.01842197],\n",
       "        [ 0.02646324, -0.01420127,  0.01776257, -0.01645806,\n",
       "          0.01392288, -0.03266357,  0.03534045, -0.00140784,\n",
       "          0.00197377, -0.01842197],\n",
       "        [ 0.02646324, -0.01420127,  0.01776257, -0.01645806,\n",
       "          0.01392288, -0.03266357,  0.03534045, -0.00140784,\n",
       "          0.00197377, -0.01842197],\n",
       "        [-0.0060734 ,  0.02152618,  0.033566  ,  0.00111835,\n",
       "         -0.00460808, -0.04044272,  0.01412145, -0.01049924,\n",
       "         -0.03695586, -0.0207214 ],\n",
       "        [-0.03826413, -0.00795293,  0.04961349,  0.02462819,\n",
       "          0.03098115,  0.02212686,  0.0107999 ,  0.01785346,\n",
       "          0.03043065,  0.03581908],\n",
       "        [-0.01527905,  0.04388886, -0.00275927,  0.03916239,\n",
       "          0.01914421,  0.04669264, -0.00490501,  0.01607584,\n",
       "          0.03569106, -0.03500973],\n",
       "        [ 0.04977628, -0.03097459,  0.03548905, -0.04400424,\n",
       "         -0.03264781,  0.02502585,  0.02545876,  0.02520918,\n",
       "         -0.03957129, -0.04557258]],\n",
       "\n",
       "       [[ 0.02646324, -0.01420127,  0.01776257, -0.01645806,\n",
       "          0.01392288, -0.03266357,  0.03534045, -0.00140784,\n",
       "          0.00197377, -0.01842197],\n",
       "        [ 0.02646324, -0.01420127,  0.01776257, -0.01645806,\n",
       "          0.01392288, -0.03266357,  0.03534045, -0.00140784,\n",
       "          0.00197377, -0.01842197],\n",
       "        [ 0.02646324, -0.01420127,  0.01776257, -0.01645806,\n",
       "          0.01392288, -0.03266357,  0.03534045, -0.00140784,\n",
       "          0.00197377, -0.01842197],\n",
       "        [-0.00792702, -0.0068443 , -0.03631203,  0.0408491 ,\n",
       "          0.04298456, -0.00781142,  0.01483749, -0.01858529,\n",
       "          0.03932463,  0.03233448],\n",
       "        [-0.02329798, -0.04330188, -0.0318718 ,  0.01619191,\n",
       "         -0.02895826,  0.00168357,  0.02291472,  0.02594021,\n",
       "         -0.04051218, -0.04285538],\n",
       "        [-0.01323009,  0.01165577, -0.04552482, -0.00890896,\n",
       "         -0.02304286,  0.02990704,  0.01552539, -0.01223302,\n",
       "         -0.04284222,  0.03085187],\n",
       "        [-0.02123238, -0.02492656, -0.04289528,  0.04128541,\n",
       "         -0.023281  , -0.02218564,  0.00079646, -0.0262629 ,\n",
       "         -0.0443431 ,  0.00755701],\n",
       "        [ 0.04238428,  0.01169572, -0.03869251,  0.04260416,\n",
       "          0.00355452,  0.02045092,  0.01434546, -0.01918657,\n",
       "         -0.0227073 , -0.03427785]],\n",
       "\n",
       "       [[ 0.02646324, -0.01420127,  0.01776257, -0.01645806,\n",
       "          0.01392288, -0.03266357,  0.03534045, -0.00140784,\n",
       "          0.00197377, -0.01842197],\n",
       "        [ 0.02646324, -0.01420127,  0.01776257, -0.01645806,\n",
       "          0.01392288, -0.03266357,  0.03534045, -0.00140784,\n",
       "          0.00197377, -0.01842197],\n",
       "        [ 0.02646324, -0.01420127,  0.01776257, -0.01645806,\n",
       "          0.01392288, -0.03266357,  0.03534045, -0.00140784,\n",
       "          0.00197377, -0.01842197],\n",
       "        [ 0.02646324, -0.01420127,  0.01776257, -0.01645806,\n",
       "          0.01392288, -0.03266357,  0.03534045, -0.00140784,\n",
       "          0.00197377, -0.01842197],\n",
       "        [-0.0060734 ,  0.02152618,  0.033566  ,  0.00111835,\n",
       "         -0.00460808, -0.04044272,  0.01412145, -0.01049924,\n",
       "         -0.03695586, -0.0207214 ],\n",
       "        [-0.04864476, -0.01736289,  0.04796194,  0.02112206,\n",
       "          0.04908483, -0.00840663,  0.00845854,  0.02431414,\n",
       "          0.01154106, -0.0079723 ],\n",
       "        [-0.01527905,  0.04388886, -0.00275927,  0.03916239,\n",
       "          0.01914421,  0.04669264, -0.00490501,  0.01607584,\n",
       "          0.03569106, -0.03500973],\n",
       "        [ 0.01238374, -0.02908298,  0.02074539, -0.01210137,\n",
       "          0.00011756,  0.01296053,  0.04638538,  0.03506866,\n",
       "         -0.04021471, -0.02119341]]], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f02c9599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMDB Project\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,SimpleRNN,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ab4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05b4c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import truststore\n",
    "truststore.inject_into_ssl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a49ce53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "URL fetch failure on https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz: None -- [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Basic Constraints of CA cert not marked critical (_ssl.c:1028)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSSLCertVerificationError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\urllib\\request.py:1319\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m     \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTransfer-encoding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1321\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\http\\client.py:1338\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1337\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\http\\client.py:1384\u001b[39m, in \u001b[36mHTTPConnection._send_request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1383\u001b[39m     body = _encode(body, \u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\http\\client.py:1333\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1333\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\http\\client.py:1093\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1096\u001b[39m \n\u001b[32m   1097\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\http\\client.py:1037\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\http\\client.py:1479\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1477\u001b[39m     server_hostname = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m-> \u001b[39m\u001b[32m1479\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1480\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\ssl.py:455\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    450\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    451\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    452\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\ssl.py:1076\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1075\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1076\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\ssl.py:1372\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1371\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1372\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mSSLCertVerificationError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Basic Constraints of CA cert not marked critical (_ssl.c:1028)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mURLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\file_utils.py:311\u001b[39m, in \u001b[36mget_file\u001b[39m\u001b[34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir, force_download)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDLProgbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m urllib.error.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\urllib\\request.py:214\u001b[39m, in \u001b[36murlretrieve\u001b[39m\u001b[34m(url, filename, reporthook, data)\u001b[39m\n\u001b[32m    212\u001b[39m url_type, path = _splittype(url)\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m contextlib.closing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m    215\u001b[39m     headers = fp.info()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\urllib\\request.py:189\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, context)\u001b[39m\n\u001b[32m    188\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\urllib\\request.py:489\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    488\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\urllib\\request.py:506\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    505\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\urllib\\request.py:466\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    465\u001b[39m func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\urllib\\request.py:1367\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1368\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\urllib\\request.py:1322\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1321\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m   1323\u001b[39m r = h.getresponse()\n",
      "\u001b[31mURLError\u001b[39m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Basic Constraints of CA cert not marked critical (_ssl.c:1028)>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m imdb  \n\u001b[32m      3\u001b[39m max_features = \u001b[32m10000\u001b[39m   \u001b[38;5;66;03m#vocab size\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m (X_train,y_train),(X_test,y_test) = \u001b[43mimdb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe training data shape : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,Training labels shape :\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_train\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe training data shape : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,Training labels shape :\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\datasets\\imdb.py:79\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m(path, num_words, skip_top, maxlen, seed, start_char, oov_char, index_from, **kwargs)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Loads the [IMDB dataset](https://ai.stanford.edu/~amaas/data/sentiment/).\u001b[39;00m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[33;03mThis is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     74\u001b[39m \u001b[33;03mhave simply been skipped.\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     76\u001b[39m origin_folder = (\n\u001b[32m     77\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps://storage.googleapis.com/tensorflow/tf-keras-datasets/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     78\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m path = \u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m=\u001b[49m\u001b[43morigin_folder\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimdb.npz\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: E501\u001b[39;49;00m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m69664113be75683a8fe16e3ed0ab59fda8886cb3cd7ada244f7d9544e4676b9f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m np.load(path, allow_pickle=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     87\u001b[39m     x_train, labels_train = f[\u001b[33m\"\u001b[39m\u001b[33mx_train\u001b[39m\u001b[33m\"\u001b[39m], f[\u001b[33m\"\u001b[39m\u001b[33my_train\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FC316LE\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\file_utils.py:315\u001b[39m, in \u001b[36mget_file\u001b[39m\u001b[34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir, force_download)\u001b[39m\n\u001b[32m    313\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg.format(origin, e.code, e.msg))\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m urllib.error.URLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg.format(origin, e.errno, e.reason))\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(download_target):\n",
      "\u001b[31mException\u001b[39m: URL fetch failure on https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz: None -- [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Basic Constraints of CA cert not marked critical (_ssl.c:1028)"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "from tensorflow.keras.datasets import imdb  \n",
    "max_features = 10000   #vocab size\n",
    "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "print(f'The training data shape : {X_train},Training labels shape :{y_train}')\n",
    "print(f'The training data shape : {X_test},Training labels shape :{y_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad22179",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
